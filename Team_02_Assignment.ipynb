{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the libraries you can use.  You may add any libraries directy related to threading if this is a direction\n",
    "#you wish to go (this is not from the course, so it's entirely on you if you wish to use threading).  Any\n",
    "#further libraries you wish to use you must email me, james@uwaterloo.ca, for permission.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns, base_optimizer\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment\n",
    "### Team Number: 02\n",
    "### Team Member Names: Jason, Patrick, Gateek\n",
    "### Team Strategy Chosen: Market Beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclose any use of AI for this assignment below (detail where and how you used it).  Please see the course outline for acceptable uses of AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: FILTER STOCKS FOR VALID TICKERS BASED ON SET REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$AGN: possibly delisted; no price data found  (period=5d) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "Failed to get ticker 'CELG' reason: Expecting value: line 1 column 1 (char 0)\n",
      "$CELG: possibly delisted; no price data found  (period=5d)\n",
      "$CL: possibly delisted; no price data found  (1d 2023-10-01 -> 2024-09-30)\n",
      "$KO: possibly delisted; no price data found  (1d 2023-10-01 -> 2024-09-30)\n",
      "$LLY: possibly delisted; no price data found  (period=5d)\n",
      "$MO: possibly delisted; no price data found  (period=5d)\n",
      "Failed to get ticker 'MON' reason: Expecting value: line 1 column 1 (char 0)\n",
      "$MON: possibly delisted; no price data found  (period=5d)\n",
      "$PFE: possibly delisted; no price data found  (1d 2023-10-01 -> 2024-09-30)\n",
      "$PM: possibly delisted; no price data found  (1d 2023-10-01 -> 2024-09-30)\n",
      "$RTN: possibly delisted; no price data found  (period=5d)\n"
     ]
    }
   ],
   "source": [
    "# valid_stocks(tickers_file) reads in a given tickers file and produces a list of tickers\n",
    "#                            that are valid according to restrictions such as currency and \n",
    "#                            average monthly volume.\n",
    "# tickers_file: csv file with tickers \n",
    "def valid_stocks(tickers_file):\n",
    "    # Read CSV and get tickers\n",
    "    tickers_df = pd.read_csv(tickers_file)\n",
    "\n",
    "    if tickers_df.empty:\n",
    "        return\n",
    "\n",
    "    tickers_df.columns = (['Tickers'])\n",
    "    tickers_list = tickers_df['Tickers'].tolist()\n",
    "\n",
    "    # Start and end dates\n",
    "    start = '2023-10-01'\n",
    "    end = '2024-09-30'\n",
    "\n",
    "    valid_tickers = []\n",
    "\n",
    "    for ticker in tickers_list:\n",
    "        # Loads in ticker info from yfinance\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.fast_info \n",
    "\n",
    "        # filter ticker by currency\n",
    "        try:\n",
    "            currency = info['currency']\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if currency != 'USD' and currency != 'CAD':\n",
    "            continue\n",
    "\n",
    "        #filter ticker by average monthly volume\n",
    "        try:\n",
    "            hist = stock.history(start=start, end=end, interval='1d')\n",
    "            hist.index = pd.to_datetime(hist.index)\n",
    "        except:\n",
    "            continue\n",
    "        monthly_volume = pd.DataFrame()\n",
    "        monthly_volume['volume'] = hist['Volume'].resample('ME').sum()\n",
    "        monthly_volume['count'] = hist['Volume'].resample('ME').count()\n",
    "        monthly_volume['avg monthly volume'] = monthly_volume['volume'] / monthly_volume['count']\n",
    "        invalid_trading_days = monthly_volume[monthly_volume['count'] < 18]\n",
    "        invalid_monthly_vol = monthly_volume[monthly_volume['avg monthly volume'] < 100000]\n",
    "\n",
    "        if len(invalid_monthly_vol) > 0 or len(invalid_trading_days) > 0:\n",
    "            continue\n",
    "\n",
    "        valid_tickers.append(ticker)\n",
    "\n",
    "    return valid_tickers\n",
    "\n",
    "valid_tickers = valid_stocks('Tickers_Example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: GET CLOSE PRICES FOR ALL VALID STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_tickers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-11-22\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     49\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2019-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 50\u001b[0m close_prices \u001b[38;5;241m=\u001b[39m get_close_prices(start, end, \u001b[43mvalid_tickers\u001b[49m, cutoff)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_tickers' is not defined"
     ]
    }
   ],
   "source": [
    "#get_close_prices(start, end, tickers, cutoff) retrieves all close prices for stocks in tickers from a start date\n",
    "#                                              to an end date. It also takes in a cutoff that excludes all stocks\n",
    "#                                              that do not have close price data before this cutoff date. Function \n",
    "#                                              will return all close prices for the valid stocks in CAD starting from the \n",
    "#                                              date at which the youngest valid stock began tracking close prices.\n",
    "# Example: get_close_prices('2020-01-01', '2024-01-01', ['AAPL', 'NVDA'], '2022-01-01')\n",
    "# Restrictions:\n",
    "#       * start < cutoff < end\n",
    "def get_close_prices(start, end, tickers, cutoff):\n",
    "\n",
    "    multi_data = pd.DataFrame()\n",
    "    df = []\n",
    "    appended_tickers = []\n",
    "\n",
    "    # loop through tickers \n",
    "    for ticker in tickers:\n",
    "        # get all data and put into a series\n",
    "        data = yf.download(ticker, start=start, end=end, interval='1d')\n",
    "        close = data['Close']\n",
    "        close = close.rename(ticker)\n",
    "\n",
    "        # if the first close price is less than cutoff\n",
    "        if close.index.min() < pd.Timestamp(cutoff):\n",
    "            # add stock close prices to df\n",
    "            df.append(close)\n",
    "            appended_tickers.append(ticker)\n",
    "\n",
    "    # create df with all the data\n",
    "    multi_data = pd.concat(df, axis=1)\n",
    "    #drop all values so that there are valid data points for each date in the index\n",
    "    multi_data.dropna(subset=appended_tickers, inplace=True)\n",
    "\n",
    "    # Get CAD->USD exchange rate\n",
    "    cadusd = yf.download('CAD=x', start=start, end=end, interval='1d')\n",
    "\n",
    "    # convert everything to CAD\n",
    "    for ticker in appended_tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.fast_info\n",
    "\n",
    "        currency = info['currency']\n",
    "        if currency == 'USD':\n",
    "            multi_data[ticker] = multi_data[ticker] * cadusd['Close']\n",
    "    \n",
    "    return multi_data\n",
    "\n",
    "start = '2015-01-01'\n",
    "end = '2024-11-22'\n",
    "cutoff = '2019-01-01'\n",
    "close_prices = get_close_prices(start, end, valid_tickers, cutoff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: REMOVES POOR PERFORMING STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticker_prices(ticker_list, start, end, interval):\n",
    "    \"\"\"\n",
    "        This function, when given a list of tickers, a start date, end date, and interval\n",
    "        will return a dataframe of the prices of the tickers from the start date to the end\n",
    "        date at the set interval\n",
    "\n",
    "        :param ticker_list: int\n",
    "        :param start: datetime\n",
    "        :param end: datetime\n",
    "        :return: dataframe\n",
    "        \"\"\"\n",
    "\n",
    "    prices = pd.DataFrame()\n",
    "\n",
    "    hist_ticker = yf.Ticker(ticker_list[0])\n",
    "    prices[ticker_list[0]] = hist_ticker.history(start=start, end=end, interval=interval).Close\n",
    "\n",
    "    ticker_list.pop(0)\n",
    "\n",
    "    for i in ticker_list:\n",
    "        hist_ticker = yf.Ticker(i)\n",
    "        prices[i] = hist_ticker.history(start=start, end=end, interval=interval).Close\n",
    "\n",
    "    return prices\n",
    "\n",
    "#feed pct_change() data\n",
    "def sort_by_sharpe(price_pct, min_sharpe, min_return, max_std):\n",
    "    \"\"\"\n",
    "        This function, when given a dataframe of\n",
    "        price percent change, a dataframe of prices, a minimum sharpe ratio, a minimum return\n",
    "        and maximum standard deviation will produce a dataframe with the returns, standard deviation\n",
    "        sharpe ratio and prices of all stocks in the given dataframe that meets the set criteria\n",
    "\n",
    "        :param price_pct: dataframe\n",
    "        :param min_sharpe: float\n",
    "        :param min_return: float\n",
    "        :param: max_std: float\n",
    "        :return: dataframe\n",
    "        \"\"\"\n",
    "\n",
    "    sharpe_df = pd.DataFrame(columns=['Returns', 'Std', 'Sharpe'])\n",
    "    returns = 0\n",
    "    std = 0\n",
    "    ticker = \"\"\n",
    "\n",
    "    stock_info = {}#fixed length list of Ticker, Returns, Std, Sharpe\n",
    "\n",
    "    tick_list = price_pct.columns\n",
    "\n",
    "    for i in range(len(tick_list)):\n",
    "        ticker = tick_list[i]\n",
    "\n",
    "        #work out equations - pct_change() on all,\n",
    "        returns = price_pct[ticker].mean()\n",
    "\n",
    "        #work out equations\n",
    "        std = price_pct[ticker].std()\n",
    "\n",
    "        #multiply sharpe_ratio by sqrt(15)\n",
    "        sharpe = returns/std * (50 ** 0.5)\n",
    "\n",
    "        #print(ticker, sharpe, returns, std)\n",
    "\n",
    "        if sharpe > min_sharpe and returns > min_return and std < max_std:\n",
    "            stock_info = {\n",
    "                'Returns': returns,\n",
    "                'Std': std,\n",
    "                'Sharpe': sharpe\n",
    "            }\n",
    "\n",
    "            # stock_info = pd.DataFrame(stock_info)\n",
    "\n",
    "            sharpe_df.loc[ticker] = stock_info\n",
    "        elif tick_list.size - sharpe_df.index.size < 12:\n",
    "            stock_info = {\n",
    "                'Returns': returns,\n",
    "                'Std': std,\n",
    "                'Sharpe': sharpe\n",
    "            }\n",
    "\n",
    "            # stock_info = pd.DataFrame(stock_info)\n",
    "\n",
    "            sharpe_df.loc[ticker] = stock_info\n",
    "\n",
    "    sharpe_df = sharpe_df.sort_values('Sharpe', ascending = False)\n",
    "\n",
    "    return sharpe_df\n",
    "\n",
    "def keep_tickers(dataframe, list):\n",
    "    \"\"\"\n",
    "    This function, given a dataframe and list of tickers, will keep\n",
    "    all items in the dataframe with a ticker in the list. Tickers must be in\n",
    "    the Dataframe\n",
    "\n",
    "    :param dataframe: pd.DataFrame\n",
    "    :param list: list[Str]\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    newframe = pd.DataFrame()\n",
    "\n",
    "    for i in list:\n",
    "        newframe[i] = dataframe[i]\n",
    "\n",
    "    return newframe\n",
    "\n",
    "def stock_df_to_ticker(dataframe):\n",
    "    \"\"\"\n",
    "        This function, when given a dataframe of stocks, will return a list of ticker strings\n",
    "\n",
    "        :param dataframe: dataframe\n",
    "        :return: list[str]\n",
    "        \"\"\"\n",
    "\n",
    "    ticker_list = []\n",
    "\n",
    "    for i in dataframe.index:\n",
    "        ticker_list.append(i)\n",
    "\n",
    "    return ticker_list\n",
    "\n",
    "def filtering(list_len, stock_correlation_tiers):\n",
    "    \"\"\"\n",
    "    This function, when given how long the list will be and categorization of stocks,\n",
    "    will return a list of stocks that we want to craft the portfolio from.\n",
    "    :param list_len: int\n",
    "    :param stock_correlation_tiers: list[list[str]]\n",
    "    :return: list[str]\n",
    "    \"\"\"\n",
    "    ticker_list = []\n",
    "    '''\n",
    "    while 0 < len(stock_correlation_tiers) and len(ticker_list) < list_len:\n",
    "        sub_list = stock_correlation_tiers[0]\n",
    "        while 0 < len(sub_list) and len(ticker_list) < list_len:\n",
    "            print(sub_list[0])\n",
    "            ticker_list.append(sub_list[0])\n",
    "            sub_list.pop(0)\n",
    "\n",
    "        stock_correlation_tiers.pop(0)\n",
    "    '''\n",
    "\n",
    "    while len(ticker_list) < list_len:\n",
    "        for i in range(len(stock_correlation_tiers)):\n",
    "            sub_list = stock_correlation_tiers[i]\n",
    "\n",
    "            if len(sub_list) > 0:\n",
    "                ticker_list.append(sub_list[0])\n",
    "                sub_list.pop(0)\n",
    "                stock_correlation_tiers[i] = sub_list\n",
    "\n",
    "    return ticker_list\n",
    "\n",
    "def arrange_by_sharpe(prices:pd.DataFrame, sharpe:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function, when given how long the list will be and categorization of stocks,\n",
    "    will return a list of stocks that we want to craft the portfolio from.\n",
    "    :param prices: pd.DataFrame\n",
    "    :param sharpe: pd.DataFrame\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    new_prices = pd.DataFrame()\n",
    "\n",
    "    for i in sharpe.index:\n",
    "        #print(i)\n",
    "        #print(prices[i])\n",
    "        new_prices[i] = prices[i]\n",
    "\n",
    "    #print(new_prices)\n",
    "\n",
    "    return new_prices\n",
    "\n",
    "def correlation_filter(prices: pd.DataFrame, max_corr: float):\n",
    "    \"\"\"\n",
    "    This function, when given a dataframe of prices and\n",
    "\n",
    "    :param prices: pd.DataFrame\n",
    "    :param max_corr: float\n",
    "    :return: list[Str]\n",
    "    \"\"\"\n",
    "    correlations = prices.corr()\n",
    "\n",
    "    tickers = []\n",
    "\n",
    "    corr_list = correlations.index\n",
    "\n",
    "    for i in range(len(corr_list)):\n",
    "        tick = corr_list[i]\n",
    "\n",
    "        if correlations.loc[tick].mean() <= max_corr:\n",
    "            tickers.append(tick)\n",
    "        elif corr_list.size - len(tickers) < 12:\n",
    "            tickers.append(tick)\n",
    "\n",
    "    return tickers\n",
    "\n",
    "def categorize(df:pd.DataFrame, pivot:str, categories:int):\n",
    "    \"\"\"\n",
    "    Categorizes stocks into different categories depending on how correlated they are\n",
    "    :param df: pd.DataFrame, must have pct data\n",
    "    :param pivot: string that is in df\n",
    "    :param categories: int\n",
    "    :return: list[list[str]]\n",
    "    \"\"\"\n",
    "    correlations = df.corr()\n",
    "    lin_space = np.linspace(0, 0.9999999, categories + 1)[1:]\n",
    "    # The 0.999999 prevents adding the stock itself into the list\n",
    "    stock_categories = []\n",
    "\n",
    "    for i in range(categories):\n",
    "        stock_categories.append([])\n",
    "\n",
    "    for stock in correlations.index:\n",
    "\n",
    "        correlation = correlations.at[pivot, stock]\n",
    "        inserted = False\n",
    "        i = 0\n",
    "        while i < categories and not inserted:\n",
    "            if correlation <= lin_space[i]:\n",
    "                stock_categories[i].append(stock)\n",
    "                inserted = True\n",
    "            i = i + 1\n",
    "    return stock_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7f/785d69cd4r94q3p9ft0h1nxr0000gn/T/ipykernel_25570/527545357.py:1: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  stock_pct_change = close_prices.pct_change()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHOP.TO</th>\n",
       "      <th>PM</th>\n",
       "      <th>BK</th>\n",
       "      <th>LLY</th>\n",
       "      <th>UNH</th>\n",
       "      <th>PG</th>\n",
       "      <th>ACN</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>C</th>\n",
       "      <th>LMT</th>\n",
       "      <th>...</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>AXP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>UNP</th>\n",
       "      <th>ABT</th>\n",
       "      <th>USB</th>\n",
       "      <th>MRK</th>\n",
       "      <th>RY.TO</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>PYPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-06</th>\n",
       "      <td>3.846000</td>\n",
       "      <td>102.426488</td>\n",
       "      <td>52.411584</td>\n",
       "      <td>108.922751</td>\n",
       "      <td>154.093850</td>\n",
       "      <td>100.975874</td>\n",
       "      <td>122.785645</td>\n",
       "      <td>27.501261</td>\n",
       "      <td>69.478465</td>\n",
       "      <td>237.132472</td>\n",
       "      <td>...</td>\n",
       "      <td>86.053392</td>\n",
       "      <td>97.872797</td>\n",
       "      <td>121.927895</td>\n",
       "      <td>121.398096</td>\n",
       "      <td>62.742535</td>\n",
       "      <td>54.997474</td>\n",
       "      <td>69.269224</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>79.607586</td>\n",
       "      <td>46.306360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-07</th>\n",
       "      <td>3.901000</td>\n",
       "      <td>104.363277</td>\n",
       "      <td>52.586736</td>\n",
       "      <td>112.325978</td>\n",
       "      <td>152.797754</td>\n",
       "      <td>103.451806</td>\n",
       "      <td>124.921978</td>\n",
       "      <td>27.642849</td>\n",
       "      <td>68.993188</td>\n",
       "      <td>240.729264</td>\n",
       "      <td>...</td>\n",
       "      <td>86.792162</td>\n",
       "      <td>98.172880</td>\n",
       "      <td>123.428181</td>\n",
       "      <td>123.732001</td>\n",
       "      <td>63.562347</td>\n",
       "      <td>55.029981</td>\n",
       "      <td>70.048935</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>79.500407</td>\n",
       "      <td>46.358357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-08</th>\n",
       "      <td>3.705000</td>\n",
       "      <td>103.730937</td>\n",
       "      <td>51.553908</td>\n",
       "      <td>110.954080</td>\n",
       "      <td>151.050149</td>\n",
       "      <td>102.993360</td>\n",
       "      <td>124.141405</td>\n",
       "      <td>27.322046</td>\n",
       "      <td>67.144703</td>\n",
       "      <td>241.682787</td>\n",
       "      <td>...</td>\n",
       "      <td>86.041873</td>\n",
       "      <td>96.558663</td>\n",
       "      <td>121.432720</td>\n",
       "      <td>121.890526</td>\n",
       "      <td>62.630240</td>\n",
       "      <td>54.262583</td>\n",
       "      <td>69.590503</td>\n",
       "      <td>75.599998</td>\n",
       "      <td>78.729708</td>\n",
       "      <td>44.127297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>3.725000</td>\n",
       "      <td>103.410392</td>\n",
       "      <td>52.176173</td>\n",
       "      <td>111.353295</td>\n",
       "      <td>151.907880</td>\n",
       "      <td>102.672117</td>\n",
       "      <td>124.425974</td>\n",
       "      <td>27.646751</td>\n",
       "      <td>68.367457</td>\n",
       "      <td>244.562280</td>\n",
       "      <td>...</td>\n",
       "      <td>86.519014</td>\n",
       "      <td>97.173180</td>\n",
       "      <td>121.880174</td>\n",
       "      <td>122.516624</td>\n",
       "      <td>62.613949</td>\n",
       "      <td>54.683782</td>\n",
       "      <td>69.693702</td>\n",
       "      <td>75.480003</td>\n",
       "      <td>78.741594</td>\n",
       "      <td>43.915049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>3.748000</td>\n",
       "      <td>104.422076</td>\n",
       "      <td>53.011739</td>\n",
       "      <td>112.213057</td>\n",
       "      <td>155.247763</td>\n",
       "      <td>102.884206</td>\n",
       "      <td>125.545425</td>\n",
       "      <td>28.184174</td>\n",
       "      <td>69.343578</td>\n",
       "      <td>246.807720</td>\n",
       "      <td>...</td>\n",
       "      <td>87.988563</td>\n",
       "      <td>98.257912</td>\n",
       "      <td>123.232278</td>\n",
       "      <td>124.325304</td>\n",
       "      <td>63.459032</td>\n",
       "      <td>55.210499</td>\n",
       "      <td>70.278752</td>\n",
       "      <td>76.580002</td>\n",
       "      <td>79.727319</td>\n",
       "      <td>44.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-12</th>\n",
       "      <td>152.259995</td>\n",
       "      <td>172.932880</td>\n",
       "      <td>108.518092</td>\n",
       "      <td>1139.975965</td>\n",
       "      <td>855.712844</td>\n",
       "      <td>230.874158</td>\n",
       "      <td>502.023207</td>\n",
       "      <td>290.834071</td>\n",
       "      <td>96.086191</td>\n",
       "      <td>787.901270</td>\n",
       "      <td>...</td>\n",
       "      <td>238.182946</td>\n",
       "      <td>401.649223</td>\n",
       "      <td>181.174406</td>\n",
       "      <td>332.598572</td>\n",
       "      <td>162.101955</td>\n",
       "      <td>70.665534</td>\n",
       "      <td>137.238154</td>\n",
       "      <td>172.750000</td>\n",
       "      <td>227.491244</td>\n",
       "      <td>120.281766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13</th>\n",
       "      <td>161.199997</td>\n",
       "      <td>174.653435</td>\n",
       "      <td>108.231024</td>\n",
       "      <td>1132.109604</td>\n",
       "      <td>844.915981</td>\n",
       "      <td>232.304136</td>\n",
       "      <td>516.290290</td>\n",
       "      <td>298.573156</td>\n",
       "      <td>96.070546</td>\n",
       "      <td>777.782325</td>\n",
       "      <td>...</td>\n",
       "      <td>237.561595</td>\n",
       "      <td>401.128373</td>\n",
       "      <td>186.423429</td>\n",
       "      <td>335.263762</td>\n",
       "      <td>161.405210</td>\n",
       "      <td>71.359119</td>\n",
       "      <td>137.363172</td>\n",
       "      <td>172.429993</td>\n",
       "      <td>223.713703</td>\n",
       "      <td>121.758154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <td>153.429993</td>\n",
       "      <td>179.386417</td>\n",
       "      <td>108.541378</td>\n",
       "      <td>1100.148070</td>\n",
       "      <td>829.977069</td>\n",
       "      <td>233.790044</td>\n",
       "      <td>506.633720</td>\n",
       "      <td>295.917626</td>\n",
       "      <td>95.360257</td>\n",
       "      <td>754.192555</td>\n",
       "      <td>...</td>\n",
       "      <td>237.358187</td>\n",
       "      <td>403.409541</td>\n",
       "      <td>185.599180</td>\n",
       "      <td>329.640043</td>\n",
       "      <td>160.958033</td>\n",
       "      <td>70.397279</td>\n",
       "      <td>137.632204</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>229.438313</td>\n",
       "      <td>120.043380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <td>152.869995</td>\n",
       "      <td>180.816821</td>\n",
       "      <td>110.087483</td>\n",
       "      <td>1049.269135</td>\n",
       "      <td>832.764177</td>\n",
       "      <td>238.398659</td>\n",
       "      <td>497.172460</td>\n",
       "      <td>284.900049</td>\n",
       "      <td>96.686876</td>\n",
       "      <td>752.051220</td>\n",
       "      <td>...</td>\n",
       "      <td>232.000693</td>\n",
       "      <td>403.382239</td>\n",
       "      <td>188.522539</td>\n",
       "      <td>331.246762</td>\n",
       "      <td>162.972785</td>\n",
       "      <td>70.166886</td>\n",
       "      <td>135.426301</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>225.687072</td>\n",
       "      <td>120.689856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18</th>\n",
       "      <td>148.990005</td>\n",
       "      <td>184.237688</td>\n",
       "      <td>110.148728</td>\n",
       "      <td>1007.556631</td>\n",
       "      <td>827.369993</td>\n",
       "      <td>239.851725</td>\n",
       "      <td>495.851478</td>\n",
       "      <td>283.228150</td>\n",
       "      <td>96.874249</td>\n",
       "      <td>743.496852</td>\n",
       "      <td>...</td>\n",
       "      <td>232.688833</td>\n",
       "      <td>400.301905</td>\n",
       "      <td>189.466172</td>\n",
       "      <td>328.588862</td>\n",
       "      <td>164.900687</td>\n",
       "      <td>70.940937</td>\n",
       "      <td>135.702442</td>\n",
       "      <td>171.580002</td>\n",
       "      <td>230.088611</td>\n",
       "      <td>118.993704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2312 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SHOP.TO          PM          BK          LLY         UNH  \\\n",
       "Date                                                                      \n",
       "2015-07-06    3.846000  102.426488   52.411584   108.922751  154.093850   \n",
       "2015-07-07    3.901000  104.363277   52.586736   112.325978  152.797754   \n",
       "2015-07-08    3.705000  103.730937   51.553908   110.954080  151.050149   \n",
       "2015-07-09    3.725000  103.410392   52.176173   111.353295  151.907880   \n",
       "2015-07-10    3.748000  104.422076   53.011739   112.213057  155.247763   \n",
       "...                ...         ...         ...          ...         ...   \n",
       "2024-11-12  152.259995  172.932880  108.518092  1139.975965  855.712844   \n",
       "2024-11-13  161.199997  174.653435  108.231024  1132.109604  844.915981   \n",
       "2024-11-14  153.429993  179.386417  108.541378  1100.148070  829.977069   \n",
       "2024-11-15  152.869995  180.816821  110.087483  1049.269135  832.764177   \n",
       "2024-11-18  148.990005  184.237688  110.148728  1007.556631  827.369993   \n",
       "\n",
       "                    PG         ACN        AMZN          C         LMT  ...  \\\n",
       "Date                                                                   ...   \n",
       "2015-07-06  100.975874  122.785645   27.501261  69.478465  237.132472  ...   \n",
       "2015-07-07  103.451806  124.921978   27.642849  68.993188  240.729264  ...   \n",
       "2015-07-08  102.993360  124.141405   27.322046  67.144703  241.682787  ...   \n",
       "2015-07-09  102.672117  124.425974   27.646751  68.367457  244.562280  ...   \n",
       "2015-07-10  102.884206  125.545425   28.184174  69.343578  246.807720  ...   \n",
       "...                ...         ...         ...        ...         ...  ...   \n",
       "2024-11-12  230.874158  502.023207  290.834071  96.086191  787.901270  ...   \n",
       "2024-11-13  232.304136  516.290290  298.573156  96.070546  777.782325  ...   \n",
       "2024-11-14  233.790044  506.633720  295.917626  95.360257  754.192555  ...   \n",
       "2024-11-15  238.398659  497.172460  284.900049  96.686876  752.051220  ...   \n",
       "2024-11-18  239.851725  495.851478  283.228150  96.874249  743.496852  ...   \n",
       "\n",
       "                  ABBV         AXP         UPS         UNP         ABT  \\\n",
       "Date                                                                     \n",
       "2015-07-06   86.053392   97.872797  121.927895  121.398096   62.742535   \n",
       "2015-07-07   86.792162   98.172880  123.428181  123.732001   63.562347   \n",
       "2015-07-08   86.041873   96.558663  121.432720  121.890526   62.630240   \n",
       "2015-07-09   86.519014   97.173180  121.880174  122.516624   62.613949   \n",
       "2015-07-10   87.988563   98.257912  123.232278  124.325304   63.459032   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-11-12  238.182946  401.649223  181.174406  332.598572  162.101955   \n",
       "2024-11-13  237.561595  401.128373  186.423429  335.263762  161.405210   \n",
       "2024-11-14  237.358187  403.409541  185.599180  329.640043  160.958033   \n",
       "2024-11-15  232.000693  403.382239  188.522539  331.246762  162.972785   \n",
       "2024-11-18  232.688833  400.301905  189.466172  328.588862  164.900687   \n",
       "\n",
       "                  USB         MRK       RY.TO        QCOM        PYPL  \n",
       "Date                                                                   \n",
       "2015-07-06  54.997474   69.269224   76.370003   79.607586   46.306360  \n",
       "2015-07-07  55.029981   70.048935   76.449997   79.500407   46.358357  \n",
       "2015-07-08  54.262583   69.590503   75.599998   78.729708   44.127297  \n",
       "2015-07-09  54.683782   69.693702   75.480003   78.741594   43.915049  \n",
       "2015-07-10  55.210499   70.278752   76.580002   79.727319   44.089600  \n",
       "...               ...         ...         ...         ...         ...  \n",
       "2024-11-12  70.665534  137.238154  172.750000  227.491244  120.281766  \n",
       "2024-11-13  71.359119  137.363172  172.429993  223.713703  121.758154  \n",
       "2024-11-14  70.397279  137.632204  172.050003  229.438313  120.043380  \n",
       "2024-11-15  70.166886  135.426301  171.130005  225.687072  120.689856  \n",
       "2024-11-18  70.940937  135.702442  171.580002  230.088611  118.993704  \n",
       "\n",
       "[2312 rows x 25 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_pct_change = close_prices.pct_change()\n",
    "\n",
    "stock_pct_change = keep_tickers(stock_pct_change, correlation_filter(stock_pct_change, 0.75))\n",
    "\n",
    "stock_sharpe = sort_by_sharpe(stock_pct_change, 0.1, 0, 1)\n",
    "\n",
    "#print(stock_sharpe)\n",
    "\n",
    "best_stock = stock_sharpe.index[0]\n",
    "\n",
    "stock_prices = arrange_by_sharpe(close_prices, stock_sharpe)\n",
    "\n",
    "stock_correlation_tiers = categorize(stock_prices, best_stock, 10)\n",
    "\n",
    "#print(stock_sharpe)\n",
    "#print(stock_correlation_tiers)\n",
    "\n",
    "ticker_lst = [best_stock]\n",
    "\n",
    "ticker_lst += filtering(24, stock_correlation_tiers)\n",
    "\n",
    "stock_close_prices = keep_tickers(close_prices, ticker_lst)\n",
    "stock_close_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAST STEP: BUY SHARES AND GENERATE PORTFOLIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following function determines the currency of each stock in our portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(tickers):\n",
    "    currencies = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.fast_info\n",
    "        currency = info['currency']\n",
    "\n",
    "        currencies.append({'Ticker': ticker, 'Currency': currency})\n",
    "        \n",
    "    df = pd.DataFrame(currencies)\n",
    "    df.set_index('Ticker', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "currencies = get_currency(valid_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following function buys our stocks based on the determined weightings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_shares(weightings_df, prices_df, currencies_df):\n",
    "\n",
    "    cash = 1000000\n",
    "    flat_fee = 3.95\n",
    "    fee_per_share = 0.001\n",
    "\n",
    "    weightings_df['Close Price'] = prices_df.reindex(weightings_df.index)\n",
    "\n",
    "    # 1: Calculate the initial investment of each stock and the amount of shares\n",
    "    weightings_df['Investment Amt'] = cash * (weightings_df['Weight'] / 100)\n",
    "    weightings_df['Shares'] = weightings_df['Investment Amt'] / weightings_df['Close Price']\n",
    "\n",
    "    # 2: Calculate the fees based on what kind of fee structure is cheaper\n",
    "    weightings_df['fees'] = np.minimum(weightings_df['Shares'] * fee_per_share, flat_fee)\n",
    "\n",
    "    # 3: Calculate total investment with fees added\n",
    "    weightings_df['Investment with fees'] = weightings_df['Shares'] * weightings_df['Close Price'] + weightings_df['fees']\n",
    "    total_with_fees = weightings_df['Investment with fees'].sum()\n",
    "\n",
    "    # 4: Adjust investment to keep the total under the budget\n",
    "    adjustment_factor = cash / total_with_fees\n",
    "    weightings_df['Adjusted Investment Amt'] = weightings_df['Investment Amt'] * adjustment_factor\n",
    "    weightings_df['Adjusted Shares'] = weightings_df['Adjusted Investment Amt'] / weightings_df['Close Price']\n",
    "\n",
    "    # 5: Recalculate fees\n",
    "    weightings_df['Adjusted fees'] = np.minimum(weightings_df['Adjusted Shares'] * fee_per_share, flat_fee)\n",
    "\n",
    "    # 6: Final investment for each stock\n",
    "    weightings_df['Final Investment'] = weightings_df['Adjusted Shares'] * weightings_df['Close Price'] + weightings_df['Adjusted fees']\n",
    "\n",
    "    # Create Final Portfolio\n",
    "    Portfolio_Final = pd.DataFrame()\n",
    "    Portfolio_Final['Ticker'] = weightings_df.index\n",
    "    Portfolio_Final.index = Portfolio_Final['Ticker']\n",
    "    Portfolio_Final['Price'] = weightings_df['Close Price']\n",
    "    Portfolio_Final['Currency'] = currencies_df.reindex(Portfolio_Final.index)['Currency'] # NEED TO FIGURE OUT A WAY TO GET ACCURATE CURRENCY DATA\n",
    "    Portfolio_Final['Shares'] = weightings_df['Adjusted Shares']\n",
    "    Portfolio_Final['Value'] = weightings_df['Adjusted Investment Amt']\n",
    "    Portfolio_Final['Weight'] = weightings_df['Weight']\n",
    "\n",
    "    Portfolio_Final.index = range(1, len(Portfolio_Final) + 1)\n",
    "\n",
    "    return Portfolio_Final\n",
    "\n",
    "weightings_df = pd.DataFrame()\n",
    "weightings_df.index = valid_tickers\n",
    "weights = [1.4999, 4.45, 1.34, 4.26, 4.23, 1.54, 1.45, 2.70, 1.85, 3.54, 4.43, 3.19, 1.39, 2.51, 3.72, 3.44, 4.43, 1.34, 3.98, 1.37, 4.14, 3.80, 1.38, 4.17, 1.61, 2.51, 2.39, 1.34, 2.27, 1.34, 1.34, 1.65, 4.21, 3.63, 4.46, 3.10]\n",
    "weightings_df['Weight'] = weights\n",
    "Portfolio_Final = buy_shares(weightings_df, close_prices.iloc[-1], currencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999989.1663796143 99.99989999999997\n"
     ]
    }
   ],
   "source": [
    "#tests\n",
    "total = Portfolio_Final['Value'].sum()\n",
    "total_weight = Portfolio_Final['Weight'].sum()\n",
    "print(total, total_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Gateek, Jason, Patrick."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
