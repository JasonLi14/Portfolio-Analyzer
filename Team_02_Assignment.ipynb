{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are the libraries you can use.  You may add any libraries directy related to threading if this is a direction\n",
    "#you wish to go (this is not from the course, so it's entirely on you if you wish to use threading).  Any\n",
    "#further libraries you wish to use you must email me, james@uwaterloo.ca, for permission.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Additional Libraries\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns, base_optimizer\n",
    "\n",
    "# Included in Python\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Tuple, List  # For documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries:\n",
    "- pandas\n",
    "- numpy\n",
    "- numpy_financial\n",
    "- yfinance\n",
    "- matplotlib\n",
    "- pypfopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment\n",
    "### Team Number: 02\n",
    "### Team Member Names: Jason, Patrick, Gateek\n",
    "### Team Strategy Chosen: Market Beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disclose any use of AI for this assignment below (detail where and how you used it).  Please see the course outline for acceptable uses of AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: FILTER STOCKS FOR VALID TICKERS BASED ON SET REQUIREMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ABBV: possibly delisted; no price data found  (period=5d)\n",
      "Failed to get ticker 'AGN' reason: HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Read timed out. (read timeout=10)\n",
      "$AGN: possibly delisted; no price data found  (period=5d) (Yahoo error = \"No data found, symbol may be delisted\")\n",
      "$AIG: possibly delisted; no price data found  (1d 2023-10-01 -> 2024-09-30)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     50\u001b[0m         valid_tickers\u001b[38;5;241m.\u001b[39mappend(ticker)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m valid_tickers\n\u001b[1;32m---> 54\u001b[0m valid_tickers \u001b[38;5;241m=\u001b[39m \u001b[43mvalid_stocks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTickers_Example.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 41\u001b[0m, in \u001b[0;36mvalid_stocks\u001b[1;34m(tickers_file)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m monthly_volume \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m---> 41\u001b[0m monthly_volume[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mhist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     42\u001b[0m monthly_volume[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m hist[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m     43\u001b[0m monthly_volume[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg monthly volume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m monthly_volume[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m monthly_volume[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\series.py:5719\u001b[0m, in \u001b[0;36mSeries.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   5704\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39mresample, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_shared_doc_kwargs)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   5705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresample\u001b[39m(\n\u001b[0;32m   5706\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5717\u001b[0m     group_keys: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5718\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Resampler:\n\u001b[1;32m-> 5719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5721\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclosed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5724\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5728\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5729\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5731\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:8888\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   8885\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresample\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_resampler\n\u001b[0;32m   8887\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8888\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_resampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   8889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSeries | DataFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8893\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8898\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8899\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   8901\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\resample.py:1523\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;124;03mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m tg \u001b[38;5;241m=\u001b[39m TimeGrouper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 1523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\resample.py:1713\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[0;32m   1706\u001b[0m         obj,\n\u001b[0;32m   1707\u001b[0m         timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1710\u001b[0m         gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[0;32m   1711\u001b[0m     )\n\u001b[1;32m-> 1713\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1714\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly valid with DatetimeIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got an instance of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ax)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1717\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "# valid_stocks(tickers_file) reads in a given tickers file and produces a list of tickers\n",
    "#                            that are valid according to restrictions such as currency and \n",
    "#                            average monthly volume.\n",
    "# tickers_file: csv file with tickers \n",
    "def valid_stocks(tickers_file):\n",
    "    # Read CSV and get tickers\n",
    "    tickers_df = pd.read_csv(tickers_file)\n",
    "\n",
    "    if tickers_df.empty:\n",
    "        return\n",
    "\n",
    "    tickers_df.columns = (['Tickers'])\n",
    "    tickers_list = tickers_df['Tickers'].tolist()\n",
    "\n",
    "    # Start and end dates\n",
    "    start = '2023-10-01'\n",
    "    end = '2024-09-30'\n",
    "\n",
    "    valid_tickers = []\n",
    "\n",
    "    for ticker in tickers_list:\n",
    "        # Loads in ticker info from yfinance\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.fast_info \n",
    "\n",
    "        # filter ticker by currency\n",
    "        try:\n",
    "            currency = info['currency']\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if currency != 'USD' and currency != 'CAD':\n",
    "            continue\n",
    "\n",
    "        #filter ticker by average monthly volume\n",
    "        try:\n",
    "            hist = stock.history(start=start, end=end, interval='1d')\n",
    "        except:\n",
    "            continue\n",
    "        monthly_volume = pd.DataFrame()\n",
    "        monthly_volume['volume'] = hist['Volume'].resample('M').sum()\n",
    "        monthly_volume['count'] = hist['Volume'].resample('M').count()\n",
    "        monthly_volume['avg monthly volume'] = monthly_volume['volume'] / monthly_volume['count']\n",
    "        invalid_trading_days = monthly_volume[monthly_volume['count'] < 18]\n",
    "        invalid_monthly_vol = monthly_volume[monthly_volume['avg monthly volume'] < 100000]\n",
    "\n",
    "        if len(invalid_monthly_vol) > 0 or len(invalid_trading_days) > 0:\n",
    "            continue\n",
    "\n",
    "        valid_tickers.append(ticker)\n",
    "\n",
    "    return valid_tickers\n",
    "\n",
    "valid_tickers = valid_stocks('Tickers_Example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: GET CLOSE PRICES FOR ALL VALID STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>AIG</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>BAC</th>\n",
       "      <th>BB.TO</th>\n",
       "      <th>BIIB</th>\n",
       "      <th>...</th>\n",
       "      <th>QCOM</th>\n",
       "      <th>RY.TO</th>\n",
       "      <th>SHOP.TO</th>\n",
       "      <th>T.TO</th>\n",
       "      <th>TD.TO</th>\n",
       "      <th>TXN</th>\n",
       "      <th>UNH</th>\n",
       "      <th>UNP</th>\n",
       "      <th>UPS</th>\n",
       "      <th>USB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-06</th>\n",
       "      <td>86.053392</td>\n",
       "      <td>62.742535</td>\n",
       "      <td>122.785645</td>\n",
       "      <td>78.018206</td>\n",
       "      <td>27.501261</td>\n",
       "      <td>97.872797</td>\n",
       "      <td>177.253338</td>\n",
       "      <td>21.368286</td>\n",
       "      <td>10.08</td>\n",
       "      <td>510.404334</td>\n",
       "      <td>...</td>\n",
       "      <td>79.607586</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>3.846000</td>\n",
       "      <td>21.870001</td>\n",
       "      <td>53.230000</td>\n",
       "      <td>64.823859</td>\n",
       "      <td>154.093850</td>\n",
       "      <td>121.398096</td>\n",
       "      <td>121.927895</td>\n",
       "      <td>54.997474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-07</th>\n",
       "      <td>86.792162</td>\n",
       "      <td>63.562347</td>\n",
       "      <td>124.921978</td>\n",
       "      <td>78.753508</td>\n",
       "      <td>27.642849</td>\n",
       "      <td>98.172880</td>\n",
       "      <td>181.217880</td>\n",
       "      <td>21.128373</td>\n",
       "      <td>10.13</td>\n",
       "      <td>516.575416</td>\n",
       "      <td>...</td>\n",
       "      <td>79.500407</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>3.901000</td>\n",
       "      <td>21.990000</td>\n",
       "      <td>52.910000</td>\n",
       "      <td>64.828277</td>\n",
       "      <td>152.797754</td>\n",
       "      <td>123.732001</td>\n",
       "      <td>123.428181</td>\n",
       "      <td>55.029981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-08</th>\n",
       "      <td>86.041873</td>\n",
       "      <td>62.630240</td>\n",
       "      <td>124.141405</td>\n",
       "      <td>77.775948</td>\n",
       "      <td>27.322046</td>\n",
       "      <td>96.558663</td>\n",
       "      <td>180.476823</td>\n",
       "      <td>20.664800</td>\n",
       "      <td>9.79</td>\n",
       "      <td>505.721692</td>\n",
       "      <td>...</td>\n",
       "      <td>78.729708</td>\n",
       "      <td>75.599998</td>\n",
       "      <td>3.705000</td>\n",
       "      <td>21.834999</td>\n",
       "      <td>52.220001</td>\n",
       "      <td>62.986309</td>\n",
       "      <td>151.050149</td>\n",
       "      <td>121.890526</td>\n",
       "      <td>121.432720</td>\n",
       "      <td>54.262583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>86.519014</td>\n",
       "      <td>62.613949</td>\n",
       "      <td>124.425974</td>\n",
       "      <td>78.614301</td>\n",
       "      <td>27.646751</td>\n",
       "      <td>97.173180</td>\n",
       "      <td>181.770122</td>\n",
       "      <td>20.977391</td>\n",
       "      <td>9.88</td>\n",
       "      <td>508.256246</td>\n",
       "      <td>...</td>\n",
       "      <td>78.741594</td>\n",
       "      <td>75.480003</td>\n",
       "      <td>3.725000</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>51.799999</td>\n",
       "      <td>61.239219</td>\n",
       "      <td>151.907880</td>\n",
       "      <td>122.516624</td>\n",
       "      <td>121.880174</td>\n",
       "      <td>54.683782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>87.988563</td>\n",
       "      <td>63.459032</td>\n",
       "      <td>125.545425</td>\n",
       "      <td>79.587512</td>\n",
       "      <td>28.184174</td>\n",
       "      <td>98.257912</td>\n",
       "      <td>183.628292</td>\n",
       "      <td>21.225033</td>\n",
       "      <td>9.75</td>\n",
       "      <td>493.424804</td>\n",
       "      <td>...</td>\n",
       "      <td>79.727319</td>\n",
       "      <td>76.580002</td>\n",
       "      <td>3.748000</td>\n",
       "      <td>21.990000</td>\n",
       "      <td>52.360001</td>\n",
       "      <td>62.289746</td>\n",
       "      <td>155.247763</td>\n",
       "      <td>124.325304</td>\n",
       "      <td>123.232278</td>\n",
       "      <td>55.210499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13</th>\n",
       "      <td>237.561595</td>\n",
       "      <td>161.405210</td>\n",
       "      <td>516.290290</td>\n",
       "      <td>106.111302</td>\n",
       "      <td>298.573156</td>\n",
       "      <td>401.128373</td>\n",
       "      <td>195.195160</td>\n",
       "      <td>63.968005</td>\n",
       "      <td>3.43</td>\n",
       "      <td>231.202429</td>\n",
       "      <td>...</td>\n",
       "      <td>223.713703</td>\n",
       "      <td>172.429993</td>\n",
       "      <td>161.199997</td>\n",
       "      <td>21.809999</td>\n",
       "      <td>78.559998</td>\n",
       "      <td>286.886821</td>\n",
       "      <td>844.915981</td>\n",
       "      <td>335.263762</td>\n",
       "      <td>186.423429</td>\n",
       "      <td>71.359119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <td>237.358187</td>\n",
       "      <td>160.958033</td>\n",
       "      <td>506.633720</td>\n",
       "      <td>105.994707</td>\n",
       "      <td>295.917626</td>\n",
       "      <td>403.409541</td>\n",
       "      <td>193.295165</td>\n",
       "      <td>64.226498</td>\n",
       "      <td>3.39</td>\n",
       "      <td>230.725639</td>\n",
       "      <td>...</td>\n",
       "      <td>229.438313</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>153.429993</td>\n",
       "      <td>21.340000</td>\n",
       "      <td>79.639999</td>\n",
       "      <td>288.249632</td>\n",
       "      <td>829.977069</td>\n",
       "      <td>329.640043</td>\n",
       "      <td>185.599180</td>\n",
       "      <td>70.397279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <td>232.000693</td>\n",
       "      <td>162.972785</td>\n",
       "      <td>497.172460</td>\n",
       "      <td>106.543980</td>\n",
       "      <td>284.900049</td>\n",
       "      <td>403.382239</td>\n",
       "      <td>197.128170</td>\n",
       "      <td>65.737512</td>\n",
       "      <td>3.33</td>\n",
       "      <td>224.969944</td>\n",
       "      <td>...</td>\n",
       "      <td>225.687072</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>152.869995</td>\n",
       "      <td>21.389999</td>\n",
       "      <td>78.800003</td>\n",
       "      <td>282.804878</td>\n",
       "      <td>832.764177</td>\n",
       "      <td>331.246762</td>\n",
       "      <td>188.522539</td>\n",
       "      <td>70.166886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18</th>\n",
       "      <td>234.220337</td>\n",
       "      <td>165.312118</td>\n",
       "      <td>496.936464</td>\n",
       "      <td>107.489496</td>\n",
       "      <td>284.112590</td>\n",
       "      <td>402.208789</td>\n",
       "      <td>202.653831</td>\n",
       "      <td>65.809325</td>\n",
       "      <td>3.37</td>\n",
       "      <td>222.472702</td>\n",
       "      <td>...</td>\n",
       "      <td>231.713048</td>\n",
       "      <td>171.600006</td>\n",
       "      <td>148.490005</td>\n",
       "      <td>21.629999</td>\n",
       "      <td>78.870003</td>\n",
       "      <td>291.831657</td>\n",
       "      <td>830.575104</td>\n",
       "      <td>330.187577</td>\n",
       "      <td>190.342768</td>\n",
       "      <td>71.288739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-19</th>\n",
       "      <td>233.571133</td>\n",
       "      <td>164.244372</td>\n",
       "      <td>496.322879</td>\n",
       "      <td>105.588679</td>\n",
       "      <td>286.912335</td>\n",
       "      <td>400.409626</td>\n",
       "      <td>204.166158</td>\n",
       "      <td>65.077960</td>\n",
       "      <td>3.27</td>\n",
       "      <td>217.950159</td>\n",
       "      <td>...</td>\n",
       "      <td>230.962966</td>\n",
       "      <td>171.690002</td>\n",
       "      <td>145.990005</td>\n",
       "      <td>21.650000</td>\n",
       "      <td>77.980003</td>\n",
       "      <td>281.948415</td>\n",
       "      <td>809.092502</td>\n",
       "      <td>327.128569</td>\n",
       "      <td>186.778369</td>\n",
       "      <td>70.672900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2313 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ABBV         ABT         ACN         AIG        AMZN  \\\n",
       "Date                                                                     \n",
       "2015-07-06   86.053392   62.742535  122.785645   78.018206   27.501261   \n",
       "2015-07-07   86.792162   63.562347  124.921978   78.753508   27.642849   \n",
       "2015-07-08   86.041873   62.630240  124.141405   77.775948   27.322046   \n",
       "2015-07-09   86.519014   62.613949  124.425974   78.614301   27.646751   \n",
       "2015-07-10   87.988563   63.459032  125.545425   79.587512   28.184174   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-11-13  237.561595  161.405210  516.290290  106.111302  298.573156   \n",
       "2024-11-14  237.358187  160.958033  506.633720  105.994707  295.917626   \n",
       "2024-11-15  232.000693  162.972785  497.172460  106.543980  284.900049   \n",
       "2024-11-18  234.220337  165.312118  496.936464  107.489496  284.112590   \n",
       "2024-11-19  233.571133  164.244372  496.322879  105.588679  286.912335   \n",
       "\n",
       "                   AXP          BA        BAC  BB.TO        BIIB  ...  \\\n",
       "Date                                                              ...   \n",
       "2015-07-06   97.872797  177.253338  21.368286  10.08  510.404334  ...   \n",
       "2015-07-07   98.172880  181.217880  21.128373  10.13  516.575416  ...   \n",
       "2015-07-08   96.558663  180.476823  20.664800   9.79  505.721692  ...   \n",
       "2015-07-09   97.173180  181.770122  20.977391   9.88  508.256246  ...   \n",
       "2015-07-10   98.257912  183.628292  21.225033   9.75  493.424804  ...   \n",
       "...                ...         ...        ...    ...         ...  ...   \n",
       "2024-11-13  401.128373  195.195160  63.968005   3.43  231.202429  ...   \n",
       "2024-11-14  403.409541  193.295165  64.226498   3.39  230.725639  ...   \n",
       "2024-11-15  403.382239  197.128170  65.737512   3.33  224.969944  ...   \n",
       "2024-11-18  402.208789  202.653831  65.809325   3.37  222.472702  ...   \n",
       "2024-11-19  400.409626  204.166158  65.077960   3.27  217.950159  ...   \n",
       "\n",
       "                  QCOM       RY.TO     SHOP.TO       T.TO      TD.TO  \\\n",
       "Date                                                                   \n",
       "2015-07-06   79.607586   76.370003    3.846000  21.870001  53.230000   \n",
       "2015-07-07   79.500407   76.449997    3.901000  21.990000  52.910000   \n",
       "2015-07-08   78.729708   75.599998    3.705000  21.834999  52.220001   \n",
       "2015-07-09   78.741594   75.480003    3.725000  21.750000  51.799999   \n",
       "2015-07-10   79.727319   76.580002    3.748000  21.990000  52.360001   \n",
       "...                ...         ...         ...        ...        ...   \n",
       "2024-11-13  223.713703  172.429993  161.199997  21.809999  78.559998   \n",
       "2024-11-14  229.438313  172.050003  153.429993  21.340000  79.639999   \n",
       "2024-11-15  225.687072  171.130005  152.869995  21.389999  78.800003   \n",
       "2024-11-18  231.713048  171.600006  148.490005  21.629999  78.870003   \n",
       "2024-11-19  230.962966  171.690002  145.990005  21.650000  77.980003   \n",
       "\n",
       "                   TXN         UNH         UNP         UPS        USB  \n",
       "Date                                                                   \n",
       "2015-07-06   64.823859  154.093850  121.398096  121.927895  54.997474  \n",
       "2015-07-07   64.828277  152.797754  123.732001  123.428181  55.029981  \n",
       "2015-07-08   62.986309  151.050149  121.890526  121.432720  54.262583  \n",
       "2015-07-09   61.239219  151.907880  122.516624  121.880174  54.683782  \n",
       "2015-07-10   62.289746  155.247763  124.325304  123.232278  55.210499  \n",
       "...                ...         ...         ...         ...        ...  \n",
       "2024-11-13  286.886821  844.915981  335.263762  186.423429  71.359119  \n",
       "2024-11-14  288.249632  829.977069  329.640043  185.599180  70.397279  \n",
       "2024-11-15  282.804878  832.764177  331.246762  188.522539  70.166886  \n",
       "2024-11-18  291.831657  830.575104  330.187577  190.342768  71.288739  \n",
       "2024-11-19  281.948415  809.092502  327.128569  186.778369  70.672900  \n",
       "\n",
       "[2313 rows x 36 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get_close_prices(start, end, tickers, cutoff) retrieves all close prices for stocks in tickers from a start date\n",
    "#                                              to an end date. It also takes in a cutoff that excludes all stocks\n",
    "#                                              that do not have close price data before this cutoff date. Function \n",
    "#                                              will return all close prices for the valid stocks in CAD starting from the \n",
    "#                                              date at which the youngest valid stock began tracking close prices.\n",
    "# Example: get_close_prices('2020-01-01', '2024-01-01', ['AAPL', 'NVDA'], '2022-01-01')\n",
    "# Restrictions:\n",
    "#       * start < cutoff < end\n",
    "def get_close_prices(start, end, tickers, cutoff):\n",
    "\n",
    "    multi_data = pd.DataFrame()\n",
    "    df = []\n",
    "    appended_tickers = []\n",
    "\n",
    "    # loop through tickers \n",
    "    for ticker in tickers:\n",
    "        # get all data and put into a series\n",
    "        data = yf.download(ticker, start=start, end=end, interval='1d')\n",
    "        close = data['Close']\n",
    "        close = close.rename(ticker)\n",
    "\n",
    "        # if the first close price is less than cutoff\n",
    "        if close.index.min() < pd.Timestamp(cutoff):\n",
    "            # add stock close prices to df\n",
    "            df.append(close)\n",
    "            appended_tickers.append(ticker)\n",
    "\n",
    "    # create df with all the data\n",
    "    multi_data = pd.concat(df, axis=1)\n",
    "    #drop all values so that there are valid data points for each date in the index\n",
    "    multi_data.dropna(subset=appended_tickers, inplace=True)\n",
    "\n",
    "    # Get CAD->USD exchange rate\n",
    "    cadusd = yf.download('CAD=x', start=start, end=end, interval='1d')\n",
    "\n",
    "    # convert everything to CAD\n",
    "    for ticker in appended_tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.fast_info\n",
    "\n",
    "        currency = info['currency']\n",
    "        if currency == 'USD':\n",
    "            multi_data[ticker] = multi_data[ticker] * cadusd['Close']\n",
    "    \n",
    "    return multi_data\n",
    "\n",
    "start = '2015-01-01'\n",
    "end = '2024-11-22'\n",
    "cutoff = '2019-01-01'\n",
    "close_prices = get_close_prices(start, end, valid_tickers, cutoff)\n",
    "\n",
    "display(close_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: REMOVES POOR PERFORMING STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_tickers(dataframe, list):\n",
    "    \"\"\"\n",
    "    This function, given a dataframe and list of tickers, will keep\n",
    "    all items in the dataframe with a ticker in the list. Tickers must be in\n",
    "    the Dataframe\n",
    "\n",
    "    :param dataframe: pd.DataFrame\n",
    "    :param list: list[Str]\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    newframe = pd.DataFrame()\n",
    "\n",
    "    for i in list:\n",
    "        newframe[i] = dataframe[i]\n",
    "\n",
    "    return newframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_df_to_ticker(dataframe):\n",
    "    \"\"\"\n",
    "        This function, when given a dataframe of stocks, will return a list of ticker strings\n",
    "\n",
    "        :param dataframe: dataframe\n",
    "        :return: list[str]\n",
    "        \"\"\"\n",
    "\n",
    "    ticker_list = []\n",
    "\n",
    "    for i in dataframe.index:\n",
    "        ticker_list.append(i)\n",
    "\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'close_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m             i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tickers\n\u001b[1;32m---> 44\u001b[0m stock_pct_change \u001b[38;5;241m=\u001b[39m \u001b[43mclose_prices\u001b[49m\u001b[38;5;241m.\u001b[39mpct_change(fill_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     45\u001b[0m stock_pct_change\u001b[38;5;241m.\u001b[39mdrop(index\u001b[38;5;241m=\u001b[39mstock_pct_change\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m stock_pct_change \u001b[38;5;241m=\u001b[39m keep_tickers(stock_pct_change, correlation_filter(stock_pct_change, \u001b[38;5;241m0.5\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'close_prices' is not defined"
     ]
    }
   ],
   "source": [
    "def correlation_filter(prices: pd.DataFrame, max_corr: float):\n",
    "    \"\"\"\n",
    "    This function, when given a dataframe of prices and\n",
    "\n",
    "    :param prices: pd.DataFrame\n",
    "    :param max_corr: float\n",
    "    :return: list[Str]\n",
    "    \"\"\"\n",
    "    correlations = prices.corr()\n",
    "\n",
    "    tickers = []\n",
    "\n",
    "    corr_list = correlations.index\n",
    "\n",
    "    avg_corr_df = pd.DataFrame(columns = ['Correlation'])\n",
    "\n",
    "     #add to a dataframe\n",
    "\n",
    "    for i in corr_list:\n",
    "        avg_corr_df.loc[i, 'Correlation'] = correlations.loc[i].mean()\n",
    "\n",
    "    avg_corr_df = avg_corr_df.sort_values('Correlation', ascending = False)\n",
    "\n",
    "    #display(avg_corr_df)\n",
    "\n",
    "    corr_list = avg_corr_df.index\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    #filter - checks the stocks near the beginning, so \n",
    "    while i < len(avg_corr_df.index):\n",
    "        index = avg_corr_df.index[i]\n",
    "        tick = corr_list[i]\n",
    "        \n",
    "        if avg_corr_df.loc[tick, 'Correlation'] <= max_corr or len(corr_list) - i <= 12:\n",
    "            tickers.append(tick)\n",
    "            i += 1\n",
    "        else:\n",
    "            print(tick + \" was removed since its correlation with other stocks was too high. (\" \n",
    "                  + str(np.round(avg_corr_df.loc[tick, 'Correlation'], 2)) + \")\")\n",
    "            i += 1\n",
    "    return tickers\n",
    "\n",
    "stock_pct_change = close_prices.pct_change(fill_method=None)\n",
    "stock_pct_change.drop(index=stock_pct_change.index[0], inplace=True)\n",
    "\n",
    "stock_pct_change = keep_tickers(stock_pct_change, correlation_filter(stock_pct_change, 0.5))\n",
    "\n",
    "display(stock_pct_change.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first round of elimination is identifying the stocks that have too high of an average correlation with the other stocks in the portfolio. So, as discussed in our Portfolio unit, we want stocks that are diversified, so we do not want to hold stocks that have too similar of a correlation with the rest of the portfolio. If the stocks in our portfolio are too closely correlated, it could result in one event causing our entire portfolio to lose value, so by having lowly correlated stocks, we can prevent that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MO was removed because its Sharpe ratio was too low. ( 0.0897 )\n",
      "BMY was removed because its Sharpe ratio was too low. ( 0.053 )\n",
      "T.TO was removed because its Sharpe ratio was too low. ( 0.0366 )\n",
      "PFE was removed because its Sharpe ratio was too low. ( 0.0316 )\n",
      "BB.TO was removed because its Sharpe ratio was too low. ( 0.0298 )\n",
      "BIIB was removed because its returns were too low. ( -0.0 )\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Returns</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SHOP.TO</th>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.036354</td>\n",
       "      <td>0.433840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLY</th>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>0.428692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.021353</td>\n",
       "      <td>0.412932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNH</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.017170</td>\n",
       "      <td>0.358869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAT</th>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.324416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.314095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TXN</th>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.018924</td>\n",
       "      <td>0.300860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LMT</th>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.289059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXP</th>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.020286</td>\n",
       "      <td>0.284160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RY.TO</th>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>0.258513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PG</th>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.249078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAC</th>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.247746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNP</th>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.240044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.238983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>0.235527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QCOM</th>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.024124</td>\n",
       "      <td>0.232881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PYPL</th>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.197599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BK</th>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.190446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.012962</td>\n",
       "      <td>0.187789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRK</th>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.186132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KO</th>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>0.183359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PM</th>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.165270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CL</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.155660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UPS</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.141255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD.TO</th>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.012538</td>\n",
       "      <td>0.137311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.021490</td>\n",
       "      <td>0.128938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIG</th>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.121788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USB</th>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.019628</td>\n",
       "      <td>0.111629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BA</th>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.110726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Returns       Std    Sharpe\n",
       "SHOP.TO  0.002230  0.036354  0.433840\n",
       "LLY      0.001131  0.018653  0.428692\n",
       "AMZN     0.001247  0.021353  0.412932\n",
       "UNH      0.000871  0.017170  0.358869\n",
       "CAT      0.000894  0.019493  0.324416\n",
       "ACN      0.000735  0.016549  0.314095\n",
       "TXN      0.000805  0.018924  0.300860\n",
       "LMT      0.000614  0.015029  0.289059\n",
       "AXP      0.000815  0.020286  0.284160\n",
       "RY.TO    0.000415  0.011339  0.258513\n",
       "PG       0.000453  0.012851  0.249078\n",
       "BAC      0.000715  0.020400  0.247746\n",
       "UNP      0.000574  0.016912  0.240044\n",
       "ABT      0.000536  0.015850  0.238983\n",
       "ABBV     0.000586  0.017607  0.235527\n",
       "QCOM     0.000794  0.024124  0.232881\n",
       "PYPL     0.000694  0.024824  0.197599\n",
       "BK       0.000487  0.018086  0.190446\n",
       "PEP      0.000344  0.012962  0.187789\n",
       "MRK      0.000384  0.014583  0.186132\n",
       "KO       0.000318  0.012252  0.183359\n",
       "PM       0.000362  0.015502  0.165270\n",
       "CL       0.000288  0.013080  0.155660\n",
       "UPS      0.000340  0.017008  0.141255\n",
       "TD.TO    0.000243  0.012538  0.137311\n",
       "C        0.000392  0.021490  0.128938\n",
       "AIG      0.000364  0.021159  0.121788\n",
       "USB      0.000310  0.019628  0.111629\n",
       "BA       0.000412  0.026333  0.110726"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feed pct_change() data\n",
    "def sort_by_sharpe(price_pct, min_sharpe, min_return, max_std):\n",
    "    \"\"\"\n",
    "        This function, when given a dataframe of\n",
    "        price percent change, a dataframe of prices, a minimum sharpe ratio, a minimum return\n",
    "        and maximum standard deviation will produce a dataframe with the returns, standard deviation\n",
    "        sharpe ratio and prices of all stocks in the given dataframe that meets the set criteria\n",
    "\n",
    "        :param price_pct: dataframe\n",
    "        :param min_sharpe: float\n",
    "        :param min_return: float\n",
    "        :param: max_std: float\n",
    "        :return: dataframe\n",
    "        \"\"\"\n",
    "\n",
    "    sharpe_df = pd.DataFrame(columns=['Returns', 'Std', 'Sharpe'])\n",
    "    returns = 0\n",
    "    std = 0\n",
    "    ticker = \"\"\n",
    "\n",
    "    stock_info = {}#fixed length list of Ticker, Returns, Std, Sharpe\n",
    "\n",
    "    tick_list = price_pct.columns\n",
    "\n",
    "    for i in range(len(tick_list)):\n",
    "        ticker = tick_list[i]\n",
    "\n",
    "        #work out equations - pct_change() on all,\n",
    "        returns = price_pct[ticker].mean()\n",
    "\n",
    "        #work out equations\n",
    "        std = price_pct[ticker].std()\n",
    "\n",
    "        #multiply sharpe_ratio by sqrt(15), or the number of weeks\n",
    "        sharpe = returns/std * (50 ** 0.5)\n",
    "\n",
    "        #print(ticker, sharpe, returns, std)\n",
    "        stock_info = {\n",
    "            'Returns': returns,\n",
    "            'Std': std,\n",
    "            'Sharpe': sharpe\n",
    "        }\n",
    "\n",
    "        # stock_info = pd.DataFrame(stock_info)\n",
    "\n",
    "        sharpe_df.loc[ticker] = stock_info\n",
    "\n",
    "    sharpe_df = sharpe_df.sort_values('Sharpe', ascending = False)\n",
    "\n",
    "    #print(sharpe_df)\n",
    "\n",
    "    #filter out the bad stocks from after the last 12 stocks, this ensures that only the worse stocks get removed. \n",
    "\n",
    "    i = 12\n",
    "\n",
    "    while i < len(sharpe_df.index):\n",
    "        index = sharpe_df.index[i]\n",
    "        \n",
    "        if sharpe_df.loc[index, 'Returns'] < min_return :\n",
    "            print(index + \" was removed because its returns were too low. (\", np.round(sharpe_df.loc[index, 'Returns'], 4), \")\")\n",
    "            sharpe_df.drop(index=index, inplace=True)\n",
    "        elif sharpe_df.loc[index, 'Std'] > max_std:\n",
    "            print(index + \" was removed because its risk was too high. (\", np.round(sharpe_df.loc[index, 'Std'], 4), \")\")\n",
    "            sharpe_df.drop(index=index, inplace=True)\n",
    "        elif sharpe_df.loc[index, 'Sharpe'] < min_sharpe:\n",
    "            print(index + \" was removed because its Sharpe ratio was too low. (\", np.round(sharpe_df.loc[index, 'Sharpe'], 4), \")\")\n",
    "            sharpe_df.drop(index=index, inplace=True)\n",
    "            \n",
    "        else:\n",
    "            i+= 1\n",
    "        \n",
    "        \n",
    "\n",
    "    #print(sharpe_df)\n",
    "\n",
    "    return sharpe_df\n",
    "\n",
    "stock_sharpe = sort_by_sharpe(stock_pct_change, 0.1, 0, 1)\n",
    "display(stock_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this step of algorithm, we sort a dataframe by their sharpe values and remove any stock whose returns or sharpe values are too low. This is to ensure that the stocks that we have are a good investment. Additionally, stocks that have too high of a risk might be removed as well. Essentially, we want to have stocks that provide positive returns and meet our criteria for our stocks.\n",
    "\n",
    "In the event that there at not 12 stocks that meet our criteria, we take the 12 that best meet our criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best stock is SHOP.TO\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def arrange_by_sharpe(prices:pd.DataFrame, sharpe:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function, when given how long the list will be and categorization of stocks,\n",
    "    will return a list of stocks that we want to craft the portfolio from.\n",
    "    :param prices: pd.DataFrame\n",
    "    :param sharpe: pd.DataFrame\n",
    "    :return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    new_prices = pd.DataFrame()\n",
    "\n",
    "    for i in sharpe.index:\n",
    "        #print(i)\n",
    "        #print(prices[i])\n",
    "        new_prices[i] = prices[i]\n",
    "\n",
    "    #print(new_prices)\n",
    "\n",
    "    return new_prices\n",
    "\n",
    "best_stock = stock_sharpe.index[0]\n",
    "\n",
    "print(\"Our best stock is \" + best_stock)\n",
    "\n",
    "stock_prices = arrange_by_sharpe(close_prices, stock_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No actual filtering occurs here, we only just shrink the list of prices to only contain the list of stocks that we wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PM', 'C', 'AIG', 'USB', 'BA'],\n",
       " ['BK'],\n",
       " [],\n",
       " [],\n",
       " ['LLY', 'LMT', 'ABBV', 'MRK', 'KO', 'CL', 'TD.TO'],\n",
       " ['UNH', 'CAT', 'AXP', 'RY.TO', 'PEP'],\n",
       " ['PG', 'BAC', 'UPS'],\n",
       " ['ACN', 'TXN', 'UNP', 'QCOM'],\n",
       " ['AMZN', 'ABT', 'PYPL'],\n",
       " []]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def categorize(df:pd.DataFrame, pivot:str, categories:int):\n",
    "    \"\"\"\n",
    "    Categorizes stocks into different categories depending on how correlated they are\n",
    "    :param df: pd.DataFrame, must have pct data\n",
    "    :param pivot: string that is in df\n",
    "    :param categories: int\n",
    "    :return: list[list[str]]\n",
    "    \"\"\"\n",
    "    correlations = df.corr()\n",
    "    lin_space = np.linspace(0, 0.9999999, categories + 1)[1:]\n",
    "    # The 0.999999 prevents adding the stock itself into the list\n",
    "    stock_categories = []\n",
    "\n",
    "    for i in range(categories):\n",
    "        stock_categories.append([])\n",
    "\n",
    "    for stock in correlations.index:\n",
    "\n",
    "        correlation = correlations.at[pivot, stock]\n",
    "        inserted = False\n",
    "        i = 0\n",
    "        while i < categories and not inserted:\n",
    "            if correlation <= lin_space[i]:\n",
    "                stock_categories[i].append(stock)\n",
    "                inserted = True\n",
    "            i = i + 1\n",
    "    return stock_categories\n",
    "\n",
    "stock_correlation_tiers = categorize(stock_prices, best_stock, 10)\n",
    "display(stock_correlation_tiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we categorize the stocks we wish to build our portfolio from based on how closely correlated they are to our best stock. Additionally, each subcategory is sorted by Sharpe ratio. This prepares our program to select the best stocks so that the stocks contained in the portfolio are not too highly correlated with the other stocks, and that the stocks with higher sharpe ratios are chosen before stocks with lower sharpe ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SHOP.TO', 'PM', 'C', 'AIG', 'USB', 'BA', 'BK', 'LLY', 'LMT', 'ABBV', 'MRK', 'KO', 'CL', 'TD.TO', 'UNH', 'CAT', 'AXP', 'RY.TO', 'PEP', 'PG', 'BAC', 'UPS', 'ACN', 'TXN', 'UNP']\n"
     ]
    }
   ],
   "source": [
    "def filtering(list_len, stock_correlation_tiers):\n",
    "    \"\"\"\n",
    "    This function, when given how long the list will be and categorization of stocks,\n",
    "    will return a list of stocks that we want to craft the portfolio from.\n",
    "    :param list_len: int\n",
    "    :param stock_correlation_tiers: list[list[str]]\n",
    "    :return: list[str]\n",
    "    \"\"\"\n",
    "    ticker_list = []\n",
    "\n",
    "    while 0 < len(stock_correlation_tiers) and len(ticker_list) < list_len:\n",
    "        sub_list = stock_correlation_tiers[0]\n",
    "        while 0 < len(sub_list) and len(ticker_list) < list_len:\n",
    "            #print(sub_list[0])\n",
    "            ticker_list.append(sub_list[0])\n",
    "            sub_list.pop(0)\n",
    "\n",
    "        stock_correlation_tiers.pop(0)\n",
    "    \n",
    "    '''\n",
    "    while len(ticker_list) < list_len:\n",
    "        for i in range(len(stock_correlation_tiers)):\n",
    "            sub_list = stock_correlation_tiers[i]\n",
    "\n",
    "            if len(sub_list) > 0:\n",
    "                ticker_list.append(sub_list[0])\n",
    "                sub_list.pop(0)\n",
    "                stock_correlation_tiers[i] = sub_list\n",
    "    '''\n",
    "\n",
    "    return ticker_list\n",
    "\n",
    "\n",
    "ticker_lst = [best_stock]\n",
    "\n",
    "ticker_lst += filtering(24, stock_correlation_tiers)\n",
    "\n",
    "print(ticker_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the filtering step, we cycle through each tier of stock correlation and add them to the list of stocks we wish to buy. This continues until we have 24 stocks (or less, if stocks we have are weak). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHOP.TO</th>\n",
       "      <th>PM</th>\n",
       "      <th>C</th>\n",
       "      <th>AIG</th>\n",
       "      <th>USB</th>\n",
       "      <th>BA</th>\n",
       "      <th>BK</th>\n",
       "      <th>LLY</th>\n",
       "      <th>LMT</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>...</th>\n",
       "      <th>CAT</th>\n",
       "      <th>AXP</th>\n",
       "      <th>RY.TO</th>\n",
       "      <th>PEP</th>\n",
       "      <th>PG</th>\n",
       "      <th>BAC</th>\n",
       "      <th>UPS</th>\n",
       "      <th>ACN</th>\n",
       "      <th>TXN</th>\n",
       "      <th>UNP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-06</th>\n",
       "      <td>3.846000</td>\n",
       "      <td>102.426488</td>\n",
       "      <td>69.478465</td>\n",
       "      <td>78.018206</td>\n",
       "      <td>54.997474</td>\n",
       "      <td>177.253338</td>\n",
       "      <td>52.411584</td>\n",
       "      <td>108.922751</td>\n",
       "      <td>237.132472</td>\n",
       "      <td>86.053392</td>\n",
       "      <td>...</td>\n",
       "      <td>104.886243</td>\n",
       "      <td>97.872797</td>\n",
       "      <td>76.370003</td>\n",
       "      <td>119.077106</td>\n",
       "      <td>100.975874</td>\n",
       "      <td>21.368286</td>\n",
       "      <td>121.927895</td>\n",
       "      <td>122.785645</td>\n",
       "      <td>64.823859</td>\n",
       "      <td>121.398096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-07</th>\n",
       "      <td>3.901000</td>\n",
       "      <td>104.363277</td>\n",
       "      <td>68.993188</td>\n",
       "      <td>78.753508</td>\n",
       "      <td>55.029981</td>\n",
       "      <td>181.217880</td>\n",
       "      <td>52.586736</td>\n",
       "      <td>112.325978</td>\n",
       "      <td>240.729264</td>\n",
       "      <td>86.792162</td>\n",
       "      <td>...</td>\n",
       "      <td>106.325463</td>\n",
       "      <td>98.172880</td>\n",
       "      <td>76.449997</td>\n",
       "      <td>122.035659</td>\n",
       "      <td>103.451806</td>\n",
       "      <td>21.128373</td>\n",
       "      <td>123.428181</td>\n",
       "      <td>124.921978</td>\n",
       "      <td>64.828277</td>\n",
       "      <td>123.732001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-08</th>\n",
       "      <td>3.705000</td>\n",
       "      <td>103.730937</td>\n",
       "      <td>67.144703</td>\n",
       "      <td>77.775948</td>\n",
       "      <td>54.262583</td>\n",
       "      <td>180.476823</td>\n",
       "      <td>51.553908</td>\n",
       "      <td>110.954080</td>\n",
       "      <td>241.682787</td>\n",
       "      <td>86.041873</td>\n",
       "      <td>...</td>\n",
       "      <td>104.621109</td>\n",
       "      <td>96.558663</td>\n",
       "      <td>75.599998</td>\n",
       "      <td>121.585325</td>\n",
       "      <td>102.993360</td>\n",
       "      <td>20.664800</td>\n",
       "      <td>121.432720</td>\n",
       "      <td>124.141405</td>\n",
       "      <td>62.986309</td>\n",
       "      <td>121.890526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>3.725000</td>\n",
       "      <td>103.410392</td>\n",
       "      <td>68.367457</td>\n",
       "      <td>78.614301</td>\n",
       "      <td>54.683782</td>\n",
       "      <td>181.770122</td>\n",
       "      <td>52.176173</td>\n",
       "      <td>111.353295</td>\n",
       "      <td>244.562280</td>\n",
       "      <td>86.519014</td>\n",
       "      <td>...</td>\n",
       "      <td>103.983203</td>\n",
       "      <td>97.173180</td>\n",
       "      <td>75.480003</td>\n",
       "      <td>120.403605</td>\n",
       "      <td>102.672117</td>\n",
       "      <td>20.977391</td>\n",
       "      <td>121.880174</td>\n",
       "      <td>124.425974</td>\n",
       "      <td>61.239219</td>\n",
       "      <td>122.516624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>3.748000</td>\n",
       "      <td>104.422076</td>\n",
       "      <td>69.343578</td>\n",
       "      <td>79.587512</td>\n",
       "      <td>55.210499</td>\n",
       "      <td>183.628292</td>\n",
       "      <td>53.011739</td>\n",
       "      <td>112.213057</td>\n",
       "      <td>246.807720</td>\n",
       "      <td>87.988563</td>\n",
       "      <td>...</td>\n",
       "      <td>104.409364</td>\n",
       "      <td>98.257912</td>\n",
       "      <td>76.580002</td>\n",
       "      <td>121.440229</td>\n",
       "      <td>102.884206</td>\n",
       "      <td>21.225033</td>\n",
       "      <td>123.232278</td>\n",
       "      <td>125.545425</td>\n",
       "      <td>62.289746</td>\n",
       "      <td>124.325304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-13</th>\n",
       "      <td>161.199997</td>\n",
       "      <td>174.653435</td>\n",
       "      <td>96.070546</td>\n",
       "      <td>106.111302</td>\n",
       "      <td>71.359119</td>\n",
       "      <td>195.195160</td>\n",
       "      <td>108.231024</td>\n",
       "      <td>1132.109604</td>\n",
       "      <td>777.782325</td>\n",
       "      <td>237.561595</td>\n",
       "      <td>...</td>\n",
       "      <td>539.788465</td>\n",
       "      <td>401.128373</td>\n",
       "      <td>172.429993</td>\n",
       "      <td>229.738169</td>\n",
       "      <td>232.304136</td>\n",
       "      <td>63.968005</td>\n",
       "      <td>186.423429</td>\n",
       "      <td>516.290290</td>\n",
       "      <td>286.886821</td>\n",
       "      <td>335.263762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-14</th>\n",
       "      <td>153.429993</td>\n",
       "      <td>179.386417</td>\n",
       "      <td>95.360257</td>\n",
       "      <td>105.994707</td>\n",
       "      <td>70.397279</td>\n",
       "      <td>193.295165</td>\n",
       "      <td>108.541378</td>\n",
       "      <td>1100.148070</td>\n",
       "      <td>754.192555</td>\n",
       "      <td>237.358187</td>\n",
       "      <td>...</td>\n",
       "      <td>542.021229</td>\n",
       "      <td>403.409541</td>\n",
       "      <td>172.050003</td>\n",
       "      <td>231.089441</td>\n",
       "      <td>233.790044</td>\n",
       "      <td>64.226498</td>\n",
       "      <td>185.599180</td>\n",
       "      <td>506.633720</td>\n",
       "      <td>288.249632</td>\n",
       "      <td>329.640043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-15</th>\n",
       "      <td>152.869995</td>\n",
       "      <td>180.816821</td>\n",
       "      <td>96.686876</td>\n",
       "      <td>106.543980</td>\n",
       "      <td>70.166886</td>\n",
       "      <td>197.128170</td>\n",
       "      <td>110.087483</td>\n",
       "      <td>1049.269135</td>\n",
       "      <td>752.051220</td>\n",
       "      <td>232.000693</td>\n",
       "      <td>...</td>\n",
       "      <td>540.060034</td>\n",
       "      <td>403.382239</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>223.043504</td>\n",
       "      <td>238.398659</td>\n",
       "      <td>65.737512</td>\n",
       "      <td>188.522539</td>\n",
       "      <td>497.172460</td>\n",
       "      <td>282.804878</td>\n",
       "      <td>331.246762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18</th>\n",
       "      <td>148.490005</td>\n",
       "      <td>185.539471</td>\n",
       "      <td>97.192707</td>\n",
       "      <td>107.489496</td>\n",
       "      <td>71.288739</td>\n",
       "      <td>202.653831</td>\n",
       "      <td>110.785602</td>\n",
       "      <td>1024.326635</td>\n",
       "      <td>747.904956</td>\n",
       "      <td>234.220337</td>\n",
       "      <td>...</td>\n",
       "      <td>541.546484</td>\n",
       "      <td>402.208789</td>\n",
       "      <td>171.600006</td>\n",
       "      <td>223.022051</td>\n",
       "      <td>240.516736</td>\n",
       "      <td>65.809325</td>\n",
       "      <td>190.342768</td>\n",
       "      <td>496.936464</td>\n",
       "      <td>291.831657</td>\n",
       "      <td>330.187577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-19</th>\n",
       "      <td>145.990005</td>\n",
       "      <td>181.646165</td>\n",
       "      <td>96.193664</td>\n",
       "      <td>105.588679</td>\n",
       "      <td>70.672900</td>\n",
       "      <td>204.166158</td>\n",
       "      <td>108.827850</td>\n",
       "      <td>1023.256595</td>\n",
       "      <td>747.758536</td>\n",
       "      <td>233.571133</td>\n",
       "      <td>...</td>\n",
       "      <td>536.118415</td>\n",
       "      <td>400.409626</td>\n",
       "      <td>171.690002</td>\n",
       "      <td>219.759060</td>\n",
       "      <td>239.446501</td>\n",
       "      <td>65.077960</td>\n",
       "      <td>186.778369</td>\n",
       "      <td>496.322879</td>\n",
       "      <td>281.948415</td>\n",
       "      <td>327.128569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2313 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SHOP.TO          PM          C         AIG        USB  \\\n",
       "Date                                                                   \n",
       "2015-07-06    3.846000  102.426488  69.478465   78.018206  54.997474   \n",
       "2015-07-07    3.901000  104.363277  68.993188   78.753508  55.029981   \n",
       "2015-07-08    3.705000  103.730937  67.144703   77.775948  54.262583   \n",
       "2015-07-09    3.725000  103.410392  68.367457   78.614301  54.683782   \n",
       "2015-07-10    3.748000  104.422076  69.343578   79.587512  55.210499   \n",
       "...                ...         ...        ...         ...        ...   \n",
       "2024-11-13  161.199997  174.653435  96.070546  106.111302  71.359119   \n",
       "2024-11-14  153.429993  179.386417  95.360257  105.994707  70.397279   \n",
       "2024-11-15  152.869995  180.816821  96.686876  106.543980  70.166886   \n",
       "2024-11-18  148.490005  185.539471  97.192707  107.489496  71.288739   \n",
       "2024-11-19  145.990005  181.646165  96.193664  105.588679  70.672900   \n",
       "\n",
       "                    BA          BK          LLY         LMT        ABBV  ...  \\\n",
       "Date                                                                     ...   \n",
       "2015-07-06  177.253338   52.411584   108.922751  237.132472   86.053392  ...   \n",
       "2015-07-07  181.217880   52.586736   112.325978  240.729264   86.792162  ...   \n",
       "2015-07-08  180.476823   51.553908   110.954080  241.682787   86.041873  ...   \n",
       "2015-07-09  181.770122   52.176173   111.353295  244.562280   86.519014  ...   \n",
       "2015-07-10  183.628292   53.011739   112.213057  246.807720   87.988563  ...   \n",
       "...                ...         ...          ...         ...         ...  ...   \n",
       "2024-11-13  195.195160  108.231024  1132.109604  777.782325  237.561595  ...   \n",
       "2024-11-14  193.295165  108.541378  1100.148070  754.192555  237.358187  ...   \n",
       "2024-11-15  197.128170  110.087483  1049.269135  752.051220  232.000693  ...   \n",
       "2024-11-18  202.653831  110.785602  1024.326635  747.904956  234.220337  ...   \n",
       "2024-11-19  204.166158  108.827850  1023.256595  747.758536  233.571133  ...   \n",
       "\n",
       "                   CAT         AXP       RY.TO         PEP          PG  \\\n",
       "Date                                                                     \n",
       "2015-07-06  104.886243   97.872797   76.370003  119.077106  100.975874   \n",
       "2015-07-07  106.325463   98.172880   76.449997  122.035659  103.451806   \n",
       "2015-07-08  104.621109   96.558663   75.599998  121.585325  102.993360   \n",
       "2015-07-09  103.983203   97.173180   75.480003  120.403605  102.672117   \n",
       "2015-07-10  104.409364   98.257912   76.580002  121.440229  102.884206   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2024-11-13  539.788465  401.128373  172.429993  229.738169  232.304136   \n",
       "2024-11-14  542.021229  403.409541  172.050003  231.089441  233.790044   \n",
       "2024-11-15  540.060034  403.382239  171.130005  223.043504  238.398659   \n",
       "2024-11-18  541.546484  402.208789  171.600006  223.022051  240.516736   \n",
       "2024-11-19  536.118415  400.409626  171.690002  219.759060  239.446501   \n",
       "\n",
       "                  BAC         UPS         ACN         TXN         UNP  \n",
       "Date                                                                   \n",
       "2015-07-06  21.368286  121.927895  122.785645   64.823859  121.398096  \n",
       "2015-07-07  21.128373  123.428181  124.921978   64.828277  123.732001  \n",
       "2015-07-08  20.664800  121.432720  124.141405   62.986309  121.890526  \n",
       "2015-07-09  20.977391  121.880174  124.425974   61.239219  122.516624  \n",
       "2015-07-10  21.225033  123.232278  125.545425   62.289746  124.325304  \n",
       "...               ...         ...         ...         ...         ...  \n",
       "2024-11-13  63.968005  186.423429  516.290290  286.886821  335.263762  \n",
       "2024-11-14  64.226498  185.599180  506.633720  288.249632  329.640043  \n",
       "2024-11-15  65.737512  188.522539  497.172460  282.804878  331.246762  \n",
       "2024-11-18  65.809325  190.342768  496.936464  291.831657  330.187577  \n",
       "2024-11-19  65.077960  186.778369  496.322879  281.948415  327.128569  \n",
       "\n",
       "[2313 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print(stock_sharpe)\n",
    "#print(stock_correlation_tiers)\n",
    "\n",
    "\n",
    "stock_close_prices = keep_tickers(close_prices, ticker_lst)\n",
    "display(stock_close_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, reduce the number of stock prices that we have in our dataframe to contain the close prices of only the stocks we wish to keep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Weightings\n",
    "In this section, we will try to find the optimal weightings with the stocks that have been chosen. We will be implementing ideas from Modern Portfolio Theory. In the next section, we will go over the theory behind this model. Then, we will implement our ideas to create a portfolio that meets our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'MSFT' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%***********************]  4 of 4 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['MSFT']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
      "['NASDAQ']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2012-11-09 -> 2024-11-09)')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-11-09</th>\n",
       "      <td>19.537857</td>\n",
       "      <td>11.3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-12</th>\n",
       "      <td>19.386786</td>\n",
       "      <td>11.3235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-13</th>\n",
       "      <td>19.389286</td>\n",
       "      <td>11.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-14</th>\n",
       "      <td>19.174286</td>\n",
       "      <td>11.1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-11-15</th>\n",
       "      <td>18.772142</td>\n",
       "      <td>11.0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker           AAPL     AMZN\n",
       "Date                          \n",
       "2012-11-09  19.537857  11.3155\n",
       "2012-11-12  19.386786  11.3235\n",
       "2012-11-13  19.389286  11.3300\n",
       "2012-11-14  19.174286  11.1475\n",
       "2012-11-15  18.772142  11.0300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THIS WILL PROBABLY BE REMOVED\n",
    "# This code block is to get stocks data\n",
    "import jason\n",
    "import markowitz\n",
    "start_date = \"2012-11-09\"\n",
    "end_date = \"2024-11-09\"\n",
    "valid_stocks = [\"AAPL\", \"MSFT\", \"AMZN\", \"NASDAQ\", \"SPY\"]\n",
    "close_prices = markowitz.getClosePrices(start_date, end_date, valid_stocks[:4], start_date)\n",
    "display(close_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "The main assumption behind the Markowitz Model is that investors are willing to accept more risk if they get more returns. In other words, the best portfolio is the one that provides the most returns for the same amount of risk. \n",
    "\n",
    "Firstly, we will plot out a portfolio that assigns random weightings to random stocks. We plot the returns on a scatter graph.\n",
    "\n",
    "Note that the following code is only an example and is not coded to be dynamic. We include a dynamic implementation in the section after."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will help simulate the randomly-weighted portfolio. The first function is to generate a list of weightings that add up to one. The second function will return a dataframe with those weightings applied. The third function gets the risk and returns of these random portfolios. The fourth function will plot it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'close_prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weightings_lst\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Example:\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest random weightings:\u001b[39m\u001b[38;5;124m\"\u001b[39m, getRandomWeightings(\u001b[38;5;28mlen\u001b[39m(\u001b[43mclose_prices\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapplyWeightings\u001b[39m(df: pd\u001b[38;5;241m.\u001b[39mDataFrame, weightings: \u001b[38;5;28mlist\u001b[39m, investment: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Returns the dataframe adjusted for all the weightings\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Requires that df has the same number of rows as the length of weightings\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'close_prices' is not defined"
     ]
    }
   ],
   "source": [
    "def getRandomWeightings(length: int, min_weight: float = 0) -> List[float]:\n",
    "    # Returns a list of random weightings\n",
    "    # Requires that the min_weight * len <= 1\n",
    "    weightings_lst = np.random.random(size=length)  # Find random weightings\n",
    "    # Make sure weightings_lst sums up to weight remainder\n",
    "    weightings_lst /= np.sum(weightings_lst)\n",
    "    weightings_lst *= 1 - min_weight\n",
    "    weightings_lst += min_weight\n",
    "    return weightings_lst.tolist()\n",
    "# Example:\n",
    "print(\"Test random weightings:\", getRandomWeightings(len(close_prices.columns), 0))\n",
    "\n",
    "\n",
    "def applyWeightings(df: pd.DataFrame, weightings: list, investment: int) -> pd.DataFrame:\n",
    "    # Returns the dataframe adjusted for all the weightings\n",
    "    # Requires that df has the same number of rows as the length of weightings\n",
    "    i = 0\n",
    "    for column in df.columns.values:\n",
    "        # find shares\n",
    "        shares = investment / df[column].iloc[0]\n",
    "        df[column] *= shares * weightings[i]\n",
    "        i = i + 1\n",
    "    return df\n",
    "# Example\n",
    "display(applyWeightings(close_prices, getRandomWeightings(len(close_prices.columns)), 1000000).head())\n",
    "\n",
    "\n",
    "def simulateRandom(tests: int, stock_data: pd.DataFrame) -> Tuple[list, list, float, float]:\n",
    "    # Simulates tests amount of tests with random weightings\n",
    "    stocks_amount = len(stock_data.columns)\n",
    "    results = [[], [], []]\n",
    "    min_std = 1000  # We want to find the minimum and maximum standard deviations later\n",
    "    max_std = -1000\n",
    "    weighting_record = []\n",
    "    for test in range(tests):  # simulate a set amount of tests\n",
    "        weightings = getRandomWeightings(stocks_amount, 0.03)\n",
    "        weighted_df = applyWeightings(stock_data, weightings, 1000000)  # Find df with weightings\n",
    "        avg_return, std = markowitz.getPortfolioResults(weighted_df)  # Find metrics for performance\n",
    "        results[0].append(avg_return)\n",
    "        results[1].append(std)\n",
    "        # Annualize Sharpe Ratio  as it is commonly meausred annualy, and \n",
    "        # we have daily data. The standard deviation does not increase \n",
    "        # at the same rate as the returns (instead, if the returns increase \n",
    "        # by x times, then the standard deviation icnreases by sqrt(x) times).\n",
    "        results[2].append(avg_return / std * (252 ** 0.5))  \n",
    "        min_std = min(std, min_std)\n",
    "        max_std = max(std, max_std)\n",
    "        weighting_record.append(weightings)\n",
    "    return results, weighting_record, min_std, max_std\n",
    "\n",
    "\n",
    "def plotSimulation(results: list):\n",
    "    x = results[1]  # Get the risk/standard deviation\n",
    "    y = results[0]  # Get the return\n",
    "    colors = results[2]  # Use Sharpe Ratio to determine color\n",
    "    plt.scatter(x, y, c=colors, cmap='summer')\n",
    "    plt.title(\"Graph of Various Weightings with the Portfolio\")\n",
    "    plt.xlabel(\"Standard Deviation\")\n",
    "    plt.ylabel(\"Average Daily Returns (%)\")\n",
    "    plt.colorbar(label=\"Sharpe Ratio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run some tests and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_results, simulation_weights, min_risk, max_risk = simulateRandom(500, close_prices)\n",
    "plotSimulation(simulation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all goes well, the random tests should be bounded above by a discernable line. All of the portfolios on this line represent the most efficient portfolio; in other words, they represent the portfolio with the highest return for roughly the same amount of risk. The portfolio we choose should line up on that line. We can then find the weightings by looping through our results list and finding the portfolio that matches our needs. \n",
    "\n",
    "However, this process is slow and unexact. Thankfully, the line, also known as the efficient frontier, that bounds the portfolios has a few special properties. Modern Portfolio Theory argues that its shape is convex, and there has been a lot of mathematical research on optimizing convex problems. We can then use the pyportfolioopt library, which gives us tools to analyze this line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with the Pyportfolioopt Library\n",
    "To have a bit more speed and accuracy in calculating the optimal portfolio, we will be using the Pyportfolioopt library (https://pyportfolioopt.readthedocs.io/en/latest/). This library implements portfolio optimization techniques, including Markowitz. This model is effective because as we have discovered, the efficient frontier can be modeled as a convex optimization problem. \n",
    "\n",
    "The general outline is that we create an ```EfficientFrontier``` class from the pyportfolioopt library, give it the expected returns of the various securities and their covariance with each other, and we input the risk that we want. Then, it will solve the optimization problem. Since we do want more returns as we are trying to aim for the market beat strategy, we have made the decision to increase our risk tolerance in exchange for more returns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Expected Returns\n",
    "The first challenge is finding a way to determine expected returns. We could use the average historical prices, but that is under the assumption that future returns will replicate previous returns. We have decided to try out the Capital Asset Pricing Model as it avoids this assumption and may be more accurate. More specifically, CAPM states that the expected return of a security can be estimated with the following formula (https://www.investopedia.com/terms/c/capm.asp#toc-capital-asset-pricing-model-capm-formula):\n",
    "\n",
    "$$R_i = R_f + \\beta(R_m - R_f)$$\n",
    "Where $R_i$ denotes the expected return of the individual security, $R_f$ is the risk-free rate, and $R_m$ is the return of the market. In other words, $R_m - R_f$ is the risk premium of the Market. The idea is that the covariance with the market is a better predictor of returns than the mean historical return.\n",
    "\n",
    "To implement CAPM, we first define the risk-free rate as $(3.31\\% + 4.41\\%)/2 = 3.86\\%$. This is the average of the Canadian 10-year benchmark bond rate (https://www.bankofcanada.ca/rates/interest-rates/lookup-bond-yields/) and the US 10-year bond rate (https://www.bloomberg.com/markets/rates-bonds/government-bonds/us). \n",
    "\n",
    "The following code first gets some market data, and then finds the beta of the securities in the stocks we choose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['^GSPC']: ReadTimeout(ReadTimeoutError(\"HTTPSConnectionPool(host='query2.finance.yahoo.com', port=443): Read timed out. (read timeout=10)\"))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'2012-11-09'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '2012-11-09'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get market data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m market_data \u001b[38;5;241m=\u001b[39m \u001b[43mmarkowitz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetClosePrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^GSPC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# I could not find the ticker for the TSX60\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# It should be \"TX60.TS\"?\u001b[39;00m\n\u001b[0;32m      4\u001b[0m display(market_data\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\markowitz.py:49\u001b[0m, in \u001b[0;36mgetClosePrices\u001b[1;34m(start, end, tickers, cutoff)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# loop through tickers\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m stock_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;66;03m# if the first close price is less than cutoff\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(\u001b[43mstock_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m):\n\u001b[0;32m     50\u001b[0m         stock_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[column], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stock_data\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:2419\u001b[0m, in \u001b[0;36m_AtIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mloc[key]\n\u001b[1;32m-> 2419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:2371\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2368\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid call for scalar access (getting)!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2370\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_key(key)\n\u001b[1;32m-> 2371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3877\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3871\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   3873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   3874\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   3875\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   3876\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 3877\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3878\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   3880\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   3881\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jiach\\.vscode\\Portfolio-Analyzer\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '2012-11-09'"
     ]
    }
   ],
   "source": [
    "# Get market data\n",
    "market_data = markowitz.getClosePrices(start_date, end_date, [\"^GSPC\"], start_date)  # I could not find the ticker for the TSX60\n",
    "# It should be \"TX60.TS\"?\n",
    "display(market_data.head())\n",
    "\n",
    "# -- Now, we find the beta -- #\n",
    "# Get stock data\n",
    "stocks = markowitz.getClosePrices(start_date, end_date, valid_stocks[1:18], start_date)  # Replace WITH EXISTING STOCK DATA\n",
    "beta_df = pd.concat([stocks, market_data], axis=1)\n",
    "beta_df.dropna(axis=0, inplace=True)\n",
    "# Find percent movement\n",
    "beta_df_pct = jason.convertToPct(beta_df)\n",
    "# Find covariance\n",
    "market_cov = beta_df_pct.cov()[\"^GSPC\"]\n",
    "# Find market variance\n",
    "market_var = beta_df_pct[\"^GSPC\"].var()\n",
    "# Find betas = cov/var\n",
    "betas = market_cov / market_var\n",
    "display(betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to find the CAPM for each stock. The following code first finds the market return as an average of market data. We will actually be using an exponentially weighted mean. This method allows more recent data to be weighted more heavily, since it makes sense that more recent data would be related to future data. \n",
    "\n",
    "To calculate exponentially weighted mean, we use the following formula:\n",
    "\n",
    "$$a_t = \\frac{c_t + c_{t-1}(1-\\alpha) + c_{t-2}(1-\\alpha)^2 + ... + c_0(1-\\alpha)^t}{1 + (1-\\alpha) + (1-\\alpha)^2 + ... + (1-\\alpha)^t}$$\n",
    "Where $t$ is the amount of periods, $c_i$ is the percent change at time $= i$, and $\\alpha$ is a factor between $0$ and $1$ that will determine how weighted previous periods are weighted. \n",
    "\n",
    "This is the code, which uses the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'market_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m market_data_pct \u001b[38;5;241m=\u001b[39m jason\u001b[38;5;241m.\u001b[39mconvertToPct(\u001b[43mmarket_data\u001b[49m)\n\u001b[0;32m      2\u001b[0m market_data_pct\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(market_data_pct\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      3\u001b[0m resampled \u001b[38;5;241m=\u001b[39m market_data_pct\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mffill()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'market_data' is not defined"
     ]
    }
   ],
   "source": [
    "market_data_pct = jason.convertToPct(market_data)\n",
    "market_data_pct.index = pd.to_datetime(market_data_pct.index)\n",
    "resampled = market_data_pct.resample(\"M\").ffill()\n",
    "market_return = resampled.ewm(alpha=0.8, adjust=True).mean()[\"^GSPC\"].iloc[-1]  # We want the last value\n",
    "print(\"Market Return (month):\", market_return)  # Remember that this is a percent, not a decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now find the expected returns using the CAPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free = 3.86\n",
    "returns = risk_free/12 + betas[:-1]  * (market_return - risk_free/12) # The risk free rate is for a year, so we divide by 12\n",
    "display(returns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have enough information to use the pyportfolioopt library. The following code file will return the Efficient Frontier object, which we will call multiple times to get various numbers. pyportfolioopt uses a covariance matrix to determine risk, which we will store with the variable cov_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     EF \u001b[38;5;241m=\u001b[39m EfficientFrontier(returns, risk, weight_bounds\u001b[38;5;241m=\u001b[39m(min_weight, max_weight))\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EF\n\u001b[1;32m----> 8\u001b[0m cov_matrix \u001b[38;5;241m=\u001b[39m jason\u001b[38;5;241m.\u001b[39mconvertToPct(\u001b[43mstocks\u001b[49m)\u001b[38;5;241m.\u001b[39mcov()\n\u001b[0;32m      9\u001b[0m display(cov_matrix\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m5\u001b[39m, :\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stocks' is not defined"
     ]
    }
   ],
   "source": [
    "def optimizedEF(returns: pd.Series, risk: pd.DataFrame, min_weight: float = 0, max_weight: float = 0.15):\n",
    "    # This will return the efficient frontier (i.e. most return for different amount of risk)\n",
    "\n",
    "    # Because there's limits, we have to incorporate them\n",
    "    EF = EfficientFrontier(returns, risk, weight_bounds=(min_weight, max_weight))\n",
    "    return EF\n",
    "\n",
    "cov_matrix = jason.convertToPct(stocks).cov()\n",
    "display(cov_matrix.iloc[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use this to solve for various portfolios. Our hypothesis is that to get a portfolio that beats the market, we have to accept more risk, even more than the optimal Sharpe ratio accounts for. To do so, we can get the risk for the optimal sharpe ratio . Then, we can use a ratio to choose a risk value that best meets our needs, i.e. create a target risk that is higher than the risk to create the optimal sharpe ratio portfolio. The ratio that we are using is gained through our own testing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m min_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mstocks\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns))  \u001b[38;5;66;03m# Find the minimum weight bound\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Find sharpe ratio portfolio\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sharpe_ef \u001b[38;5;241m=\u001b[39m optimizedEF(returns, cov_matrix, min_weight)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stocks' is not defined"
     ]
    }
   ],
   "source": [
    "min_weight = 1 / (2 * len(stocks.columns))  # Find the minimum weight bound\n",
    "\n",
    "# Find sharpe ratio portfolio\n",
    "sharpe_ef = optimizedEF(returns, cov_matrix, min_weight)\n",
    "sharpe_weights = sharpe_ef.max_sharpe(risk_free/100)\n",
    "sharpe_risk = sharpe_ef.portfolio_performance(risk_free_rate=risk_free/100)[1]\n",
    "\n",
    "# Find target risk\n",
    "target_risk = sharpe_risk * 1.1\n",
    "target_ef = optimizedEF(returns, cov_matrix, min_weight)\n",
    "target_weights = target_ef.efficient_risk(target_risk)\n",
    "wanted_weights = target_ef.clean_weights()\n",
    "target_performance = target_ef.portfolio_performance(risk_free_rate=risk_free/100)\n",
    "\n",
    "# Display results\n",
    "print(wanted_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAST STEP: BUY SHARES AND GENERATE PORTFOLIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following function determines the currency of each stock in our portfolio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(tickers):\n",
    "    currencies = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.fast_info\n",
    "        currency = info['currency']\n",
    "\n",
    "        currencies.append({'Ticker': ticker, 'Currency': currency})\n",
    "        \n",
    "    df = pd.DataFrame(currencies)\n",
    "    df.set_index('Ticker', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "currencies = get_currency(valid_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following function buys our stocks based on the determined weightings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_shares(weightings_df, prices_df, currencies_df):\n",
    "\n",
    "    cash = 1000000\n",
    "    flat_fee = 3.95\n",
    "    fee_per_share = 0.001\n",
    "\n",
    "    weightings_df['Close Price'] = prices_df.reindex(weightings_df.index)\n",
    "\n",
    "    # 1: Calculate the initial investment of each stock and the amount of shares\n",
    "    weightings_df['Investment Amt'] = cash * (weightings_df['Weight'] / 100)\n",
    "    weightings_df['Shares'] = weightings_df['Investment Amt'] / weightings_df['Close Price']\n",
    "\n",
    "    # 2: Calculate the fees based on what kind of fee structure is cheaper\n",
    "    weightings_df['fees'] = np.minimum(weightings_df['Shares'] * fee_per_share, flat_fee)\n",
    "\n",
    "    # 3: Calculate total investment with fees added\n",
    "    weightings_df['Investment with fees'] = weightings_df['Shares'] * weightings_df['Close Price'] + weightings_df['fees']\n",
    "    total_with_fees = weightings_df['Investment with fees'].sum()\n",
    "\n",
    "    # 4: Adjust investment to keep the total under the budget\n",
    "    adjustment_factor = cash / total_with_fees\n",
    "    weightings_df['Adjusted Investment Amt'] = weightings_df['Investment Amt'] * adjustment_factor\n",
    "    weightings_df['Adjusted Shares'] = weightings_df['Adjusted Investment Amt'] / weightings_df['Close Price']\n",
    "\n",
    "    # 5: Recalculate fees\n",
    "    weightings_df['Adjusted fees'] = np.minimum(weightings_df['Adjusted Shares'] * fee_per_share, flat_fee)\n",
    "\n",
    "    # 6: Final investment for each stock\n",
    "    weightings_df['Final Investment'] = weightings_df['Adjusted Shares'] * weightings_df['Close Price'] + weightings_df['Adjusted fees']\n",
    "\n",
    "    # Create Final Portfolio\n",
    "    Portfolio_Final = pd.DataFrame()\n",
    "    Portfolio_Final['Ticker'] = weightings_df.index\n",
    "    Portfolio_Final.index = Portfolio_Final['Ticker']\n",
    "    Portfolio_Final['Price'] = weightings_df['Close Price']\n",
    "    Portfolio_Final['Currency'] = currencies_df.reindex(Portfolio_Final.index)['Currency'] # NEED TO FIGURE OUT A WAY TO GET ACCURATE CURRENCY DATA\n",
    "    Portfolio_Final['Shares'] = weightings_df['Adjusted Shares']\n",
    "    Portfolio_Final['Value'] = weightings_df['Adjusted Investment Amt']\n",
    "    Portfolio_Final['Weight'] = weightings_df['Weight']\n",
    "\n",
    "    Portfolio_Final.index = range(1, len(Portfolio_Final) + 1)\n",
    "\n",
    "    return Portfolio_Final\n",
    "\n",
    "weightings_df = pd.DataFrame()\n",
    "weightings_df.index = valid_tickers\n",
    "weights = [1.4999, 4.45, 1.34, 4.26, 4.23, 1.54, 1.45, 2.70, 1.85, 3.54, 4.43, 3.19, 1.39, 2.51, 3.72, 3.44, 4.43, 1.34, 3.98, 1.37, 4.14, 3.80, 1.38, 4.17, 1.61, 2.51, 2.39, 1.34, 2.27, 1.34, 1.34, 1.65, 4.21, 3.63, 4.46, 3.10]\n",
    "weightings_df['Weight'] = weights\n",
    "Portfolio_Final = buy_shares(weightings_df, close_prices.iloc[-1], currencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests\n",
    "total = Portfolio_Final['Value'].sum()\n",
    "total_weight = Portfolio_Final['Weight'].sum()\n",
    "print(total, total_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Gateek, Jason, Patrick."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
